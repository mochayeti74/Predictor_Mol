{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINADO Y CURACION DE DATOS, EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos el instalador de CHEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código instala el paquete de Python llamado Chembl_WebResource_Client. \n",
    "# Este paquete proporciona una interfaz de programación de aplicaciones (API)\n",
    "# para acceder a los recursos en línea de ChEMBL, una base de datos química y biológica. Esta API permite a los desarrolladores crear aplicaciones \n",
    "# que puedan interactuar con la base de datos ChEMBL para recuperar información sobre compuestos químicos, actividad biológica, estructuras moleculares y más.\n",
    "! pip install chembl_webresource_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos módulos necesarios\n",
    "# pandas: biblioteca de Python que proporciona estructuras de datos y herramientas de análisis de datos de alto rendimiento.\n",
    "import pandas as pd\n",
    "# chembl_webresource_client: módulo que proporciona una API para acceder a los datos del Depósito ChEMBL.\n",
    "from chembl_webresource_client.new_client import new_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos el target TRPM8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar el recurso \"target\" del cliente `new_client` para acceder a los datos del Depósito ChEMBL sobre objetivos biológicos.\n",
    "target = new_client.target\n",
    "# Buscar targets en el Depósito ChEMBL que coincidan con el término \"TRPM8\"\n",
    "target_query = target.search('TRPM8')\n",
    "# Guardar los resultados de la consulta en un DataFrame de pandas llamado `targets`\n",
    "targets = pd.DataFrame.from_dict(target_query)\n",
    "# Imprimir el DataFrame `targets`\n",
    "targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajaremos con el target Homo sapiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el cuarto elemento (índice 3) de la columna `target_chembl_id` del DataFrame `targets`\n",
    "# Almacenar el valor seleccionado (3, homo sapiens) en la variable `selected_target3`\n",
    "selected_target3 = targets.target_chembl_id[3]\n",
    "# Imprimir el valor almacenado en `selected_target3`\n",
    "selected_target3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalamos librerias necesarias para convertir a excel un DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instala dos módulos de Python: openpyxl y xlwt.\n",
    "# openpyxl: permite trabajar con archivos de Microsoft Excel en formato .xlsx en Python\n",
    "%pip install openpyxl\n",
    "# xlwt: permite crear archivos de Microsoft Excel en formato .xls en Python\n",
    "%pip install xlwt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe sin modificar de Homo Sapiens, para poder comparar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar el recurso \"activity\" del cliente `new_client` para acceder a los datos del Depósito ChEMBL.\n",
    "activity0 = new_client.activity\n",
    "# Ejecutar una consulta para obtener la actividad de moléculas en el target seleccionado previamente (identificado por `selected_target3`)\n",
    "res0 = activity0.get(target_chembl_id=selected_target3)\n",
    "# Guardar los resultados de la consulta en un DataFrame de pandas llamado `df_sinmodificar`\n",
    "df_sinmodificar = pd.DataFrame.from_dict(res0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe con los datos de TRPM8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el valor almacenado en `df_sinmodificar`\n",
    "df_sinmodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame `df_sinmodificar` en un archivo de Microsoft Excel con el nombre \"Datos_sin_Modificar_IC50_EC50_PIC50_PEC50.xlsx\"\n",
    "df_sinmodificar.to_excel('Datos_sin_Modificar_IC50_EC50_PIC50_PEC50.xlsx')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filtramos EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar el recurso \"activity\" del cliente `new_client` para acceder a los datos del Depósito ChEMBL.\n",
    "activity3EC50 = new_client.activity\n",
    "# Almacenar los resultados de la consulta en la variable `res3EC50` filtrado con target EC50\n",
    "res3EC50 = activity3EC50.filter(target_chembl_id=selected_target3).filter(standard_type=\"EC50\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtramos IC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar el recurso \"activity\" del cliente `new_client` para acceder a los datos del Depósito ChEMBL.\n",
    "activity3 = new_client.activity\n",
    "# Almacenar los resultados de la consulta en la variable `res3` filtrado con target IC50\n",
    "res3 = activity3.filter(target_chembl_id=selected_target3).filter(standard_type=\"IC50\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasamos a DF EC50, lo llamamos df3EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar los resultados de la consulta en la variable `df3EC50` para cambiar el nombre del dataframe a df3EC50\n",
    "df3EC50 = pd.DataFrame.from_dict(res3EC50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasamos a DF EC50, lo llamamos df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la lista de diccionarios almacenada en `res3` en un DataFrame de pandas y almacenar el resultado en la variable `df3`\n",
    "df3 = pd.DataFrame.from_dict(res3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostramos el df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el valor almacenado en `df3`\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3`\n",
    "# Mostrar el resultado\n",
    "df3['molecule_chembl_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostramos el df3EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el contenido del DataFrame `df3EC50`\n",
    "df3EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3EC50`\n",
    "# Mostrar el resultado\n",
    "df3EC50['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quitamos pEC50 de df3EC50 y los contamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame `df3EC50` para incluir solo las filas donde el valor en la columna `type` sea distinto de \"pEC50\"\n",
    "# Almacenar el resultado en un nuevo DataFrame llamado `df3EC50_sinPEC50`\n",
    "df3EC50_sinPEC50 = df3EC50[df3EC50.type != 'pEC50']\n",
    "# Contar el número de veces que aparece cada valor en la columna `type` del DataFrame `df3EC50_sinPEC50`, para ver si solamente hay EC50.\n",
    "df3EC50_sinPEC50['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3EC50_sinPEC50`, para notar si se modifico el numero de moleculas al hacer el filtrado de \"pEC50\"\n",
    "df3EC50_sinPEC50['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quitamos pIC50 de df3 y los contamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame `df3` para incluir solo las filas donde el valor en la columna `type` sea distinto de \"pIC50\"\n",
    "# Almacenar el resultado en un nuevo DataFrame llamado `df3_sinpIC50`\n",
    "df3_sinpIC50 = df3[df3.type != 'pIC50']\n",
    "# Contar el número de veces que aparece cada valor en la columna `type` del DataFrame `df3_sinpIC50`, para ver si solamente hay IC50.\n",
    "df3_sinpIC50['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3_sinpIC50`\n",
    "df3_sinpIC50['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtramos las palabras mutants en df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame `df3_sinpIC50` para excluir las filas cuyo valor en la columna `assay_description` contenga la palabra \"mutant\" (en cualquier forma, ya sea con mayúsculas o minúsculas)\n",
    "df3_sinMutants_IC50 = df3_sinpIC50[~df3_sinpIC50['assay_description'].str.contains(\"mutant\")]\n",
    "df3_sinMutants_IC50 = df3_sinMutants_IC50[~df3_sinMutants_IC50['assay_description'].str.contains(\"Mutant\")]\n",
    "df3_sinMutants_IC50 = df3_sinMutants_IC50[~df3_sinMutants_IC50['assay_description'].str.contains(\"MUTANT\")]\n",
    "df3_sinMutants_IC50 = df3_sinMutants_IC50[~df3_sinMutants_IC50['assay_description'].str.contains(\"Mutants\")]\n",
    "df3_sinMutants_IC50 = df3_sinMutants_IC50[~df3_sinMutants_IC50['assay_description'].str.contains(\"MUTANTS\")]\n",
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3_sinMutants_IC50`\n",
    "df3_sinMutants_IC50['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos sin mutants hay en la columna `molecule_chembl_id` del DataFrame `df3_sinMutants_IC50`\n",
    "df3_sinMutants_IC50['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtramos las palabras mutants en df3EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame `df3EC50_sinMutants_EC50` para excluir las filas cuyo valor en la columna `assay_description` contenga la palabra \"mutant\" (en cualquier forma, ya sea con mayúsculas o minúsculas)\n",
    "df3EC50_sinMutants_EC50 = df3EC50_sinPEC50[~df3EC50_sinPEC50['assay_description'].str.contains(\"mutant\")]\n",
    "df3EC50_sinMutants_EC50 = df3EC50_sinMutants_EC50[~df3EC50_sinMutants_EC50['assay_description'].str.contains(\"Mutant\")]\n",
    "df3EC50_sinMutants_EC50 = df3EC50_sinMutants_EC50[~df3EC50_sinMutants_EC50['assay_description'].str.contains(\"MUTANT\")]\n",
    "df3EC50_sinMutants_EC50 = df3EC50_sinMutants_EC50[~df3EC50_sinMutants_EC50['assay_description'].str.contains(\"Mutants\")]\n",
    "df3EC50_sinMutants_EC50 = df3EC50_sinMutants_EC50[~df3EC50_sinMutants_EC50['assay_description'].str.contains(\"MUTANTS\")]\n",
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3EC50_sinMutants_EC50`\n",
    "df3EC50_sinMutants_EC50['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3EC50_sinMutants_EC50`\n",
    "df3EC50_sinMutants_EC50['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIN MUTANT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de veces que aparece cada valor en la columna `type` del DataFrame `df3EC50_sinMutants_EC50`\n",
    "df3EC50_sinMutants_EC50['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de veces que aparece cada valor en la columna `type` del DataFrame `df3_sinMutants_IC50`\n",
    "df3_sinMutants_IC50['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3_sinMutants_IC50`\n",
    "df3_sinMutants_IC50['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En esta columna buscamos un valor especifico CHEMBL2442030 para comprobar la unidad en la que esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar el dato \"CHEMBL2442030\" en la columna \"molecule_chembl_id\" \n",
    "CHEMBL2442030 = df3_sinMutants_IC50[df3_sinMutants_IC50.molecule_chembl_id == 'CHEMBL2442030']\n",
    "# Mostrar el contenido de las columnas `value`, `standard_units` y `units` del DataFrame \n",
    "print(CHEMBL2442030['value'])\n",
    "print(CHEMBL2442030['standard_units'])\n",
    "print(CHEMBL2442030['units'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pasamos los valores a uM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear cinco DataFrames a partir de `df3_sinMutants_IC50` que incluyen solo las filas con ciertos valores específicos en la columna `molecule_chembl_id` o `units`\n",
    "df_nM0 = df3_sinMutants_IC50[df3_sinMutants_IC50.molecule_chembl_id.isin(['CHEMBL1289953','CHEMBL4446849','CHEMBL4454519','CHEMBL4458679','CHEMBL4517528'])]\n",
    "df_nM0\n",
    "df_nM = df3_sinMutants_IC50[df3_sinMutants_IC50.units == 'nM']\n",
    "df_nM\n",
    "# Convertir el tipo de datos de la columna `value` del DataFrame `df_nM` a float\n",
    "df_nM['value'] = df_nM['value'].astype(float)\n",
    "# Dividir el valor de cada fila en la columna `value` del DataFrame `df_nM` por 1000\n",
    "df_nM['value'] = df_nM['value']/1000\n",
    "# Establecer la opción para mostrar valores float con 10 dígitos decimales\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
    "df_nM\n",
    "# Cambiar el valor de la columna `units` en todas las filas del DataFrame `df_nM` a \"µM\"\n",
    "df_nM['units'] = 'µM'\n",
    "df_nM\n",
    "df_µM2 = df3_sinMutants_IC50[df3_sinMutants_IC50.units == 'µM']\n",
    "df_µM2\n",
    "df_uM3 = df3_sinMutants_IC50[df3_sinMutants_IC50.units == 'uM']\n",
    "df_uM3\n",
    "df_um4 = df3_sinMutants_IC50[df3_sinMutants_IC50.units == 'um']\n",
    "df_um4\n",
    "# Concatenar los cuatro DataFrames mencionados anteriormente en un único DataFrame llamado `df3_Pasando_valores_a_uM`\n",
    "df3_Pasando_valores_a_uM =  pd.concat([df_nM0,df_nM,df_µM2,df_uM3,df_um4])\n",
    "# Cambiar el valor de la columna `units` en todas las filas del DataFrame `df3_Pasando_valores_a_uM` a \"µM\"\n",
    "df3_Pasando_valores_a_uM['units'] = 'µM'\n",
    "# Cambiar el valor de la columna `standard_units` en todas las filas del DataFrame `df3_Pasando_valores_a_uM` a \"µM\"\n",
    "df3_Pasando_valores_a_uM['standard_units'] = 'µM'\n",
    "# Muestra el Df\n",
    "df3_Pasando_valores_a_uM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismo proceso que el anterior pero con EC50.\n",
    "df_nMEC50=df3EC50_sinMutants_EC50\n",
    "df_nMEC50['value'] = df_nMEC50['value'].astype(float)\n",
    "df_nMEC50 = df3EC50_sinMutants_EC50[df3EC50_sinMutants_EC50.units == 'nM']\n",
    "df_nMEC50\n",
    "df_nMEC50['value'] = df3EC50_sinMutants_EC50['value'].astype(float)\n",
    "df_nMEC50['value'] = df3EC50_sinMutants_EC50['value']/1000\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
    "df_nMEC50\n",
    "df_nMEC50['units'] = 'µM'\n",
    "df_nMEC50\n",
    "df_µM2EC50 = df3EC50_sinMutants_EC50[df3EC50_sinMutants_EC50.units == 'µM']\n",
    "df_µM2EC50\n",
    "df_uM3EC50 = df3EC50_sinMutants_EC50[df3EC50_sinMutants_EC50.units == 'uM']\n",
    "df_uM3EC50\n",
    "df_um4EC50 = df3EC50_sinMutants_EC50[df3EC50_sinMutants_EC50.units == 'um']\n",
    "df_um4EC50\n",
    "df3EC50_Pasando_valores_a_uM =  pd.concat([df_nMEC50,df_µM2EC50,df_uM3EC50,df_um4EC50])\n",
    "df3EC50_Pasando_valores_a_uM['units'] = 'µM'\n",
    "df3EC50_Pasando_valores_a_uM['standard_units'] = 'µM'\n",
    "df3EC50_Pasando_valores_a_uM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobamos que se realizo correctamente la transformacion a uM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar el dato \"CHEMBL2442030\" en la columna \"molecule_chembl_id\" \n",
    "CHEMBL2442030 = df3_Pasando_valores_a_uM[df3_Pasando_valores_a_uM.molecule_chembl_id == 'CHEMBL2442030']\n",
    "# Mostrar el contenido de las columnas `value`, `standard_units` y `units` del DataFrame \n",
    "print(CHEMBL2442030['value'])\n",
    "print(CHEMBL2442030['standard_units'])\n",
    "print(CHEMBL2442030['units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar el dato \"CHEMBL391997\" en la columna \"molecule_chembl_id\" \n",
    "CHEMBL391997 = df3_Pasando_valores_a_uM[df3_Pasando_valores_a_uM.molecule_chembl_id == 'CHEMBL391997']\n",
    "# Mostrar el contenido de las columnas `value`, `standard_units` y `units` del DataFrame \n",
    "print(CHEMBL391997['value'])\n",
    "print(CHEMBL391997['standard_units'])\n",
    "print(CHEMBL391997['units'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenamos ambos dataframe para realizar busqueda de valores que tengan EC50 Y IC50 a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos ambos dataframe para realizar busqueda de valores que tengan EC50 Y IC50 a la vez\n",
    "dataframes_uM_concatenados = pd.concat([df3_Pasando_valores_a_uM, df3EC50_Pasando_valores_a_uM], ignore_index=True)\n",
    "dataframes_uM_concatenados\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sacamos los duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame llamado `dataframes_uM_concatenados_duplicados` a partir de `dataframes_uM_concatenados` que incluye solo las filas con valores duplicados en la columna `molecule_chembl_id`\n",
    "# Pero manteniendo todas las filas duplicadas en lugar de solo una de ellas\n",
    "dataframes_uM_concatenados_duplicados = dataframes_uM_concatenados[dataframes_uM_concatenados.duplicated(['molecule_chembl_id'], keep=False)]\n",
    "dataframes_uM_concatenados_duplicados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOLECULA CON AMBOS VALORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos la Molecula CHEMBL256087 la cual tiene valores de IC50 y EC50 al mismo tiempo.\n",
    "buscarCHEMBL256087 = dataframes_uM_concatenados_duplicados[dataframes_uM_concatenados_duplicados.molecule_chembl_id == 'CHEMBL256087']\n",
    "buscarCHEMBL256087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMBL256087 = df3_Pasando_valores_a_uM[df3_Pasando_valores_a_uM.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMBL256087 = df3EC50_Pasando_valores_a_uM[df3EC50_Pasando_valores_a_uM.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUPLICADOS SOLO DE IC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame llamado `dataframes_uM_IC50_duplicados` a partir de `dataframes_uM_concatenados_duplicados` que incluye solo las filas con el valor \"IC50\" duplicado en la columna `standard_type`\n",
    "dataframes_uM_IC50_duplicados = dataframes_uM_concatenados_duplicados[dataframes_uM_concatenados_duplicados.standard_type == 'IC50']\n",
    "dataframes_uM_IC50_duplicados\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTEO DE DUPLICADOS IC50 Y EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta los valores duplicados que hay en el df dataframes_uM_concatenados_duplicados\n",
    "dataframes_uM_concatenados_duplicados['type'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUPLICADOS EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra los duplicados de EC50 \n",
    "dataframes_uM_EC50_duplicados9 = dataframes_uM_concatenados_duplicados[dataframes_uM_concatenados_duplicados.standard_type == 'EC50']\n",
    "dataframes_uM_EC50_duplicados9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME DUPLICADOS IC50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_duplicados = dataframes_uM_IC50_duplicados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta los valores duplicados que hay en el df df3_duplicados\n",
    "df3_duplicados['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar las filas del DataFrame `df3_duplicados` por el valor en la columna `molecule_chembl_id`\n",
    "# y contar el número de filas en cada grupo\n",
    "df3_duplicados.groupby('molecule_chembl_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame llamado `df3EC50_duplicados` a partir de `df3EC50_Pasando_valores_a_uM` que incluye solo las filas con valores duplicados en la columna `molecule_chembl_id`\n",
    "# pero manteniendo todas las filas duplicadas en lugar de solo una de ellas\n",
    "df3EC50_duplicados = df3EC50_Pasando_valores_a_uM[df3EC50_Pasando_valores_a_uM.duplicated(['molecule_chembl_id'], keep=False)]\n",
    "# Contar el número de veces que aparece cada valor único en la columna `type` y mostrar el resultado\n",
    "df3EC50_duplicados['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar las filas del DataFrame `df3EC50_duplicados` por el valor en la columna `molecule_chembl_id`\n",
    "# y contar el número de filas en cada grupo\n",
    "df3EC50_duplicados.groupby('molecule_chembl_id').count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNICA MOLECULA QUE TIENE AMBOS VALORES- IC50 Y EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame llamado `ambos_valores` que incluye la molecula CHEMBL256087 que tiene valores de IC50 y EC50\n",
    "ambos_valores = df3_Pasando_valores_a_uM[df3_Pasando_valores_a_uM['molecule_chembl_id'] == 'CHEMBL256087']\n",
    "ambos_valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame llamado `ambos_valores2` que incluye la molecula CHEMBL256087 que tiene valores de IC50 y EC50\n",
    "ambos_valores2 = df3EC50_Pasando_valores_a_uM[df3EC50_Pasando_valores_a_uM['molecule_chembl_id'] == 'CHEMBL256087']\n",
    "ambos_valores2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUITAMOS LOS DUPLICADOS DE LOS DATAFRAMES "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME SIN DUPLICADOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame llamado `df3_SIN_DUPLICADOS` eliminando todas las filas que tienen valores duplicados en la columna `molecule_chembl_id`\n",
    "# del DataFrame `df3_Pasando_valores_a_uM`\n",
    "df3_SIN_DUPLICADOS = df3_Pasando_valores_a_uM.drop_duplicates(subset=['molecule_chembl_id'], keep=False)\n",
    "# Contar el número de veces que aparece cada valor único en la columna `type` y mostrar el resultado como una serie de datos\n",
    "df3_SIN_DUPLICADOS['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores únicos en la columna `molecule_chembl_id` del DataFrame `df3_SIN_DUPLICADOS`\n",
    "df3_SIN_DUPLICADOS['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando todas las filas que tienen valores duplicados en la columna `molecule_chembl_id`\n",
    "df3EC50_SIN_DUPLICADOS = df3EC50_Pasando_valores_a_uM.drop_duplicates(subset=['molecule_chembl_id'], keep=False)\n",
    "# Contar el número de valores de `molecule_chembl_id` del DataFrame `df3EC50_SIN_DUPLICADOS`\n",
    "df3EC50_SIN_DUPLICADOS['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de valores unicos de `molecule_chembl_id` del DataFrame `df3EC50_SIN_DUPLICADOS`\n",
    "df3EC50_SIN_DUPLICADOS['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando desviacion estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una nueva columna al DataFrame `df3_duplicados` que contenga el valor de la desviación estándar de los valores en la columna `value`\n",
    "# agrupados por el valor de la columna `molecule_chembl_id`\n",
    "df3_duplicados['std'] = df3_duplicados.groupby('molecule_chembl_id')['value'].transform('std')\n",
    "df3_duplicados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una nueva columna al DataFrame `df3EC50_duplicados` que contenga el valor de la desviación estándar de los valores en la columna `value`\n",
    "# agrupados por el valor de la columna `molecule_chembl_id`\n",
    "df3EC50_duplicados['std'] = df3EC50_duplicados.groupby('molecule_chembl_id')['value'].transform('std')\n",
    "df3EC50_duplicados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sacando la media de df3_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores de la columna `value y std` del DataFrame `df3_duplicados` en tipo `float`\n",
    "df3_duplicados['value'] = df3_duplicados['value'].astype(float)\n",
    "df3_duplicados['std'] = df3_duplicados['std'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores de la columna `value y std` del DataFrame `df3EC50_duplicados` en tipo `float`\n",
    "df3EC50_duplicados['value'] = df3EC50_duplicados['value'].astype(float)\n",
    "df3EC50_duplicados['std'] = df3EC50_duplicados['std'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una nueva columna al DataFrame `df3_duplicados` que contenga el valor mediano de los valores en la columna `value`\n",
    "# agrupados por el valor de la columna `molecule_chembl_id`\n",
    "df3_duplicados['median'] = df3_duplicados.groupby('molecule_chembl_id')['value'].transform('median')\n",
    "df3_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una nueva columna al DataFrame `df3EC50_duplicados` que contenga el valor mediano de los valores en la columna `value`\n",
    "# agrupados por el valor de la columna `molecule_chembl_id`\n",
    "df3EC50_duplicados['median'] = df3EC50_duplicados.groupby('molecule_chembl_id')['value'].transform('median')\n",
    "df3EC50_duplicados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando el dato CHEMBL256087 de IC50, ya que tiene valores de EC50 tambien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando el dato CHEMBL256087 de IC50, ya que tiene valores de EC50 tambien\n",
    "df3EC50_SIN_DUPLICADOS = df3EC50_SIN_DUPLICADOS[df3EC50_SIN_DUPLICADOS.molecule_chembl_id != 'CHEMBL256087']\n",
    "df3_duplicados= df3_duplicados[df3_duplicados.molecule_chembl_id != 'CHEMBL256087']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando que el dato ya no existe en ese Df\n",
    "CHEMBL256087 = df3EC50_SIN_DUPLICADOS[df3EC50_SIN_DUPLICADOS.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando que el dato ya no existe en ese Df\n",
    "CHEMBL256087 = df3_duplicados[df3_duplicados.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando el indice 1 indicado por los profesores ya que usaremos valores de literatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando el indice 1\n",
    "df3EC50_duplicados = df3EC50_duplicados.drop([1])\n",
    "df3EC50_duplicados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3_SIN_DUPLICADOS['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3_SIN_DUPLICADOS['type'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mayores a 3 DESVIACION ESTANDAR DUPLICADOS IC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame que contenga solo las filas del DataFrame `df3_duplicados` cuyo valor en la columna `std` es mayor a 3\n",
    "df3_duplicadosmayora3 = df3_duplicados[df3_duplicados['std'] > 3]\n",
    "df3_duplicadosmayora3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los valores unicos de df3_duplicadosmayora3\n",
    "df3_duplicadosmayora3['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MENORES A 3 DESVIACION ESTANDAR DUPLICADOS IC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos que contenga solo las filas del DataFrame `df3_duplicados` cuyo valor en la columna `std` es menor a 3\n",
    "df3_duplicados = df3_duplicados[df3_duplicados['std'] <= 3]\n",
    "df3_duplicados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los valores unicos.\n",
    "df3_duplicados['molecule_chembl_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos df3_SIN_DUPLICADOS \n",
    "df3_SIN_DUPLICADOS['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos df3EC50_SIN_DUPLICADOS \n",
    "df3EC50_SIN_DUPLICADOS['type'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe de duplicados, sin duplicados (unicos) aplicando la media en value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores en la columna `value` del DataFrame `df3_duplicados` con los valores correspondientes en la columna `median`\n",
    "df3_duplicados['value'] = df3_duplicados['median']\n",
    "df3_duplicados = df3_duplicados.drop_duplicates(subset=['molecule_chembl_id'], keep='first')\n",
    "df3_duplicados = df3_duplicados.drop(['median'], axis=1)\n",
    "df3_duplicados = df3_duplicados.drop(['std'], axis=1)\n",
    "df3_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los datos que nos quedaron en el df df3_duplicados luego de filtrar los datos mayores a 3 y dejar la media de los datos duplicados.\n",
    "df3_duplicados['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismo procedimiento que el anterior pero en el df df3EC50_duplicados\n",
    "df3EC50_duplicados['value'] = df3EC50_duplicados['median']\n",
    "df3EC50_duplicados = df3EC50_duplicados.drop_duplicates(subset=['molecule_chembl_id'], keep='first')\n",
    "df3EC50_duplicados = df3EC50_duplicados.drop(['median'], axis=1)\n",
    "df3EC50_duplicados = df3EC50_duplicados.drop(['std'], axis=1)\n",
    "df3EC50_duplicados\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agregando los datos a sus respectivos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos los datos filtrados a DF3_NORMALIZADO.\n",
    "DF3_NORMALIZADO = df3_SIN_DUPLICADOS.append(df3_duplicados)\n",
    "# Contamos los valores.\n",
    "DF3_NORMALIZADO['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos los datos filtrados a DF3_EC50_NORMAALIZADO\n",
    "DF3_EC50_NORMAALIZADO = df3EC50_SIN_DUPLICADOS.append(df3EC50_duplicados)\n",
    "# Contamos los valores.\n",
    "DF3_EC50_NORMAALIZADO['type'].value_counts()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrando los Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3_EC50_NORMAALIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3_NORMALIZADO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAMBIANDO COMA POR PUNTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"value\" del dataframe DF3_NORMALIZADO a tipo de dato \"str\"\n",
    "DF3_NORMALIZADO['value'] = DF3_NORMALIZADO['value'].astype(str)\n",
    "# Convertir la columna \"value\" del dataframe DF3_EC50_NORMAALIZADO a tipo de dato \"str\"\n",
    "DF3_EC50_NORMAALIZADO['value'] = DF3_EC50_NORMAALIZADO['value'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar todas las comas por puntos en la columna \"value\" \n",
    "DF3_NORMALIZADO['value'] = DF3_NORMALIZADO['value'].str.replace(',', '.')\n",
    "DF3_EC50_NORMAALIZADO['value'] = DF3_EC50_NORMAALIZADO['value'].str.replace(',', '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"value\" del dataframe DF3_NORMALIZADO a tipo de dato \"float\"\n",
    "DF3_NORMALIZADO['value'] = DF3_NORMALIZADO['value'].astype(float)\n",
    "DF3_EC50_NORMAALIZADO['value'] = DF3_EC50_NORMAALIZADO['value'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3_NORMALIZADO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGREGANDO VALOR DE LITERATURA A DATO QUE TENIA AMBOS VALORES( IC50 Y EC50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar un valor de literatura a una fila específica del dataframe DF3_EC50_NORMAALIZADO\n",
    "DF3_EC50_NORMAALIZADO.loc[DF3_EC50_NORMAALIZADO['molecule_chembl_id'] == 'CHEMBL256087', 'value'] = 350\n",
    "DF3_EC50_NORMAALIZADO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar la biblioteca \"matplotlib\" utilizando pip\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código importa el módulo \"pyplot\" de la biblioteca de visualización de datos \"matplotlib\" y lo renombra como \"plt\".\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear histograma de la columna \"value\"\n",
    "DF3_NORMALIZADO['value'].hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear diagrama de caja de la columna \"value\" del dataframe \n",
    "DF3_NORMALIZADO.boxplot(column=['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear diagrama de caja de la columna \"value\" del dataframe \n",
    "DF3_EC50_NORMAALIZADO.boxplot(column=['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear histograma de la columna \"value\" del dataframe \n",
    "DF3_EC50_NORMAALIZADO['value'].hist(bins=50)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPROBANDO QUE EL DATO QUE TENIA AMBOS VALORES SOLO ESTE EN DATAFRAME EC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hace para buscar el dato con identificador \"CHEMBL256087\" en el dataframe DF3_NORMALIZADO\n",
    "CHEMBL256087 = DF3_NORMALIZADO[DF3_NORMALIZADO.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087\n",
    "\n",
    "DF3_NORMALIZADO = DF3_NORMALIZADO[DF3_NORMALIZADO.molecule_chembl_id != 'CHEMBL256087']\n",
    "DF3_NORMALIZADO\n",
    "CHEMBL256087 = DF3_NORMALIZADO[DF3_NORMALIZADO.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hace para buscar el dato con identificador \"CHEMBL256087\" en el dataframe DF3_NORMALIZADO\n",
    "CHEMBL256087 = DF3_EC50_NORMAALIZADO[DF3_EC50_NORMAALIZADO.molecule_chembl_id == 'CHEMBL256087']\n",
    "CHEMBL256087\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPROBANDO NULOS EN EL DATAFRAME EN LA CATEGORIA \"VALUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hace para comprobar que no haya valores \"NaN\" o \"Not a Number\" en la columna \"value\" del dataframe DF3_NORMALIZADO\n",
    "DF3_NORMALIZADO[DF3_NORMALIZADO['value'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hace para comprobar que no haya valores \"NaN\" o \"Not a Number\" en la columna \"value\" del dataframe DF3_EC50_NORMAALIZADO\n",
    "DF3_EC50_NORMAALIZADO[DF3_EC50_NORMAALIZADO['value'].isnull()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPROBANDO NULOS EN CATEGORIA \"SMILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hace para comprobar que no haya valores \"NaN\" o \"Not a Number\" en la columna \"canonical_smiles\" del dataframe DF3_NORMALIZADO\n",
    "DF3_NORMALIZADO[DF3_NORMALIZADO['canonical_smiles'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hace para comprobar que no haya valores \"NaN\" o \"Not a Number\" en la columna \"canonical_smiles\" del dataframe DF3_EC50_NORMAALIZADO\n",
    "DF3_EC50_NORMAALIZADO[DF3_EC50_NORMAALIZADO['canonical_smiles'].isnull()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUSCANDO EN LITERATURA EL SMILE DE LOS DATOS PERDIDOS EN CATEGORIA SMILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos sin canonical_smiles\n",
    "df3_nulos = DF3_NORMALIZADO[DF3_NORMALIZADO['canonical_smiles'].isnull()]\n",
    "df3_nulos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mostrando solo su id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando el molecule_chembl_id de df3_nulos\n",
    "df3_nulos['molecule_chembl_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instala seaborn\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO HAY DATOS DE LAS MOLECULAS EN CUESTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar los módulos \"matplotlib\", \"numpy\" y \"pandas\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Crear un gráfico de barras a partir de los datos de la columna \"value\" del dataframe DF3_EC50_NORMAALIZADO\n",
    "DF3_EC50_NORMAALIZADO['value'].plot(kind='bar')\n",
    "# Establecer el tamaño del gráfico\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "# Ocultar las etiquetas del eje x del gráfico\n",
    "plt.xticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un histograma a partir de los datos de la columna \"value\" del dataframe DF3_NORMALIZADO, dividiendo los datos en 50 intervalos o bin\n",
    "DF3_NORMALIZADO['value'].hist(bins=50)\n",
    "# Crear un histograma a partir de los datos de la columna \"value\" del dataframe DF3_EC50_NORMAALIZADO, dividiendo los datos en 50 intervalos o bin\n",
    "DF3_EC50_NORMAALIZADO['value'].hist(bins=50)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME IC50 NORMALIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3_NORMALIZADO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF EC50 NORMALIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3_EC50_NORMAALIZADO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARANDO COLUMNAS RELEVANTES ('value', 'canonical_smiles', 'molecule_chembl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe llamado \"df3_class\" que contenga solo las columnas \"value\", \"canonical_smiles\" y \"molecule_chembl_id\" del dataframe DF3_NORMALIZADO\n",
    "df3_class = DF3_NORMALIZADO[['value', 'canonical_smiles', 'molecule_chembl_id']]\n",
    "df3_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo dataframe llamado \"df3_class2\" que contenga solo las columnas \"value\", \"canonical_smiles\" y \"molecule_chembl_id\" del dataframe DF3_EC50_NORMAALIZADO\n",
    "df3_class2 =  DF3_EC50_NORMAALIZADO[['value', 'canonical_smiles', 'molecule_chembl_id']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando los datos que no tenian smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas que contengan valores nulos en cualquiera de sus columnas\n",
    "df3_class = df3_class.dropna()\n",
    "# Eliminar las filas que contengan una cadena vacía en la columna \"canonical_smiles\"\n",
    "df3_class = df3_class[df3_class.canonical_smiles != '']\n",
    "# Mostrar el dataframe \"df3_class\"\n",
    "df3_class\n",
    "#se eliminaron 6 que no tenian smile y no fue posible recuperarlos de chembl."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIPINSKI 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este código importa la biblioteca de química RDKit y usa sus funciones para calcular los descriptores moleculares para un conjunto de datos. Está calculando el peso molecular (MW), el logaritmo del punto de fusión (LogP), el número de donantes de hidrógeno (NumHDonors) y el número de aceptores de hidrógeno (NumHAcceptors) para cada molécula en el conjunto de datos. Estos descriptores se utilizan comúnmente para predecir la solubilidad y absorción oral en los estudios farmacocinéticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar los módulos \"Chem\" y \"Descriptors\" de la biblioteca \"rdkit\"\n",
    "# Importar el módulo \"Lipinski\" de la biblioteca \"rdkit\"\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski\n",
    "# Añadir una nueva columna al dataframe \"df3_class\" con el peso molecular de las moléculas\n",
    "df3_class['MW'] = df3_class.canonical_smiles.apply(lambda x: Descriptors.MolWt(Chem.MolFromSmiles(x)))\n",
    "# Añadir una nueva columna al dataframe \"df3_class\" con el coeficiente de distribución octanol-agua de las moléculas\n",
    "df3_class['LogP'] = df3_class.canonical_smiles.apply(lambda x: Descriptors.MolLogP(Chem.MolFromSmiles(x)))\n",
    "# Añadir una nueva columna al dataframe \"df3_class\" con el número de átomos de hidrógeno que actúan como donadores de enlaces en las moléculas\n",
    "df3_class['NumHDonors'] = df3_class.canonical_smiles.apply(lambda x: Lipinski.NumHDonors(Chem.MolFromSmiles(x)))\n",
    "# Añadir una nueva columna al dataframe \"df3_class\" con el número de átomos que actúan como aceptores de enlaces en las moléculas\n",
    "df3_class['NumHAcceptors'] = df3_class.canonical_smiles.apply(lambda x: Lipinski.NumHAcceptors(Chem.MolFromSmiles(x)))\n",
    "# Añadir una nueva columna al dataframe \"df3_class\" con el número de átomos de hidrógeno que actúan como donadores de enlaces en las moléculas\n",
    "df3_class['NumHBondDonors'] = df3_class.canonical_smiles.apply(lambda x: Lipinski.NumHDonors(Chem.MolFromSmiles(x)))\n",
    "# Añadir una nueva columna al dataframe \"df3_class\" con el número de átomos que actúan como aceptores de enlaces en las moléculas\n",
    "df3_class['NumHBondAcceptors'] = df3_class.canonical_smiles.apply(lambda x: Lipinski.NumHAcceptors(Chem.MolFromSmiles(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las filas que tienen valores \"NaN\" en el dataframe \"df3_class2\"\n",
    "df3_class2 = df3_class2.dropna()\n",
    "# Elimina las filas que tienen cadenas vacías en la columna \"canonical_smiles\" del dataframe \"df3_class2\"\n",
    "df3_class2 = df3_class2[df3_class2.canonical_smiles != '']\n",
    "df3_class2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski\n",
    "df3_class2['MW'] = df3_class2.canonical_smiles.apply(lambda x: Descriptors.MolWt(Chem.MolFromSmiles(x)))\n",
    "df3_class2['LogP'] = df3_class2.canonical_smiles.apply(lambda x: Descriptors.MolLogP(Chem.MolFromSmiles(x)))\n",
    "df3_class2['NumHDonors'] = df3_class2.canonical_smiles.apply(lambda x: Lipinski.NumHDonors(Chem.MolFromSmiles(x)))\n",
    "df3_class2['NumHAcceptors'] = df3_class2.canonical_smiles.apply(lambda x: Lipinski.NumHAcceptors(Chem.MolFromSmiles(x)))\n",
    "df3_class2['NumHBondDonors'] = df3_class2.canonical_smiles.apply(lambda x: Lipinski.NumHDonors(Chem.MolFromSmiles(x)))\n",
    "df3_class2['NumHBondAcceptors'] = df3_class2.canonical_smiles.apply(lambda x: Lipinski.NumHAcceptors(Chem.MolFromSmiles(x)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando IC50 O EC50 para diferenciarlos despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una nueva columna al dataframe \"df3_class2\" llamada \"type\" y asignarle a todas las filas el valor \"EC50\"\n",
    "df3_class2['type'] = 'EC50'\n",
    "df3_class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una nueva columna al dataframe \"df3_class\" llamada \"type\" y asignarle a todas las filas el valor \"IC50\"\n",
    "df3_class['type'] = 'IC50'\n",
    "df3_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenando ambos df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los dataframes \"df3_class\" y \"df3_class2\" en un nuevo dataframe \"df3_class\"\n",
    "df3_class = pd.concat([df3_class, df3_class2], axis=0)\n",
    "df3_class\n",
    "# Reindexar el dataframe \"df3_class\" y eliminar las etiquetas de índice antiguas\n",
    "df3_class = df3_class.reset_index(drop=True)\n",
    "df3_class\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cambiando a nM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicar todos los valores de la columna \"value\" del dataframe \"df3_class\" por 1000\n",
    "df3_class['value'] = df3_class['value']*1000\n",
    "df3_class\n",
    "# Renombrar la columna \"value\" del dataframe \"df3_class\" a \"value_nM\"\n",
    "df3_class = df3_class.rename(columns={'value': 'value_nM'})\n",
    "df3_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la biblioteca \"numpy\" como \"np\"\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una nueva columna al dataframe \"df3_class\" llamada \"value_Molar\", que contiene los valores de \"value_nM\" convertidos a Molar\n",
    "df3_class['value_Molar'] = df3_class['value_nM'].apply(lambda x: 10**(-9)*x)\n",
    "df3_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una nueva columna al dataframe \"df3_class\" llamada \"log10_value_Molar\", que contiene el logaritmo base 10 de los valores de \"value_Molar\"\n",
    "df3_class['log10_value_Molar'] = df3_class['value_Molar'].apply(lambda x:-np.log10(x))\n",
    "# Renombrar la columna \"log10_value_Molar\" a \"PIC50\"\n",
    "df3_class = df3_class.rename(columns={'log10_value_Molar': 'PIC50'})\n",
    "df3_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUITANDO COLUMNAS NO RELEVANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas \"value_nM\", \"value_Molar\" y \"canonical_smiles\" del dataframe \"df3_class\" y almacenar el resultado en un nuevo dataframe llamado \"df3_class_columnasrelevantes\"\n",
    "df3_class_columnasrelevantes=df3_class.drop(['value_nM', 'value_Molar', 'canonical_smiles'], axis=1)\n",
    "df3_class_columnasrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas \"value_nM\", \"value_Molar\" y \"canonical_smiles\" del dataframe \"df3_class\" y almacenar el resultado en un nuevo dataframe llamado \"graficos\"\n",
    "graficos = df3_class \n",
    "graficos = graficos.drop(['value_nM', 'value_Molar', 'canonical_smiles'], axis=1)\n",
    "graficos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIPOS DE DATOS EN DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el tipo de datos de la columna \"type\" a cadena (str)\n",
    "graficos['type'] = graficos['type'].astype(str)\n",
    "# Mostrar los tipos de datos de cada columna del dataframe\n",
    "graficos.dtypes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREANDO COLUMNA type_num para poder graficar con type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columna \"type_num\" que contenga un número entero según el valor de la columna \"type\"\n",
    "# Si \"type\" es \"IC50\", \"type_num\" tendrá el valor 1\n",
    "# Si \"type\" es \"EC50\", \"type_num\" tendrá el valor 2\n",
    "graficos['type_num'] = graficos['type'].apply(lambda x: 1 if x == 'IC50' else 2)\n",
    "graficos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando librerias y paletas de Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código importa varias paletas de colores de Bokeh, una biblioteca de Python para crear gráficos interactivos. Estas paletas incluyen Spectral6, Category20c, Category20b, Category20, Category10 y otros. También importa varias funciones de Bokeh como figure, show, ColumnDataSource y Legend. Finalmente, también se usa output_notebook() para mostrar los gráficos en un cuaderno Jupyter.\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.palettes import Category20b\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.models import Legend\n",
    "from bokeh.palettes import cividis\n",
    "from bokeh.palettes import Pastel1\n",
    "from bokeh.palettes import PuRd\n",
    "from bokeh.palettes import inferno\n",
    "from bokeh.palettes import PuOr\n",
    "from bokeh.palettes import Purples\n",
    "from bokeh.palettes import Turbo256\n",
    "from bokeh.palettes import RdPu\n",
    "from bokeh.palettes import Purples\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.palettes import Category20b\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.models import Legend\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import Legend\n",
    "output_notebook()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DINAMICOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los siguientes codigos en la seccion DINAMICOS crean diferentes tipos de graficos como de línea, scatter, wisker, barras con Bokeh y colores para un conjunto de datos específico (df). Toma los parámetros columna_x, columna_y, título, nombre de archivo, nombrex y nombrey para construir el gráfico. El gráfico se guarda como un archivo HTML con el nombre especificado en el parámetro nombre de archivo. El gráfico contiene líneas y círculos que se colorean según la columna 'type' del conjunto de datos df, además de etiquetas en los ejes x e y especificadas por los parámetros nombrex y nombrey respectivamente. El gráfico también contiene herramientas hover que muestran información adicional sobre los puntos del gráfico cuando se pasan por encima con el cursor del mouse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import PolySelectTool\n",
    "from bokeh.models import CrosshairTool, HoverTool\n",
    "#La función grafico_scatter_bokeh() permite generar un gráfico de dispersión utilizando la librería Bokeh en Python.\n",
    "#Recibe como parámetros el dataframe que contiene los datos, el nombre de la columna para el eje x, \n",
    "# el nombre de la columna para el eje y, el título del gráfico, el nombre del archivo a guardar, \n",
    "# el título del eje x y el título del eje y. Además, la función agrega herramientas de hover y leyenda al gráfico para facilitar \n",
    "# la interpretación de los datos.\n",
    "def grafico_scatter_bokeh(df,columna_x,columna_y,titulo,nombre_archivo,nombrex,nombrey):\n",
    "    df=df.sort_values(by=columna_x)\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(plot_width=800, plot_height=400,title=titulo)\n",
    "    p.circle(columna_x, columna_y, source=source, size=10, color=\"blue\", alpha=0.5)\n",
    "    p.xaxis.axis_label = nombrex\n",
    "    p.yaxis.axis_label = nombrey\n",
    "    p.xaxis.axis_label_text_alpha = 1\n",
    "    p.yaxis.axis_label_text_alpha = 1\n",
    "    p.xaxis.axis_label_text_font = \"times\"\n",
    "    p.yaxis.axis_label_text_font = \"times\"\n",
    "    p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p.xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.yaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.xaxis.axis_label_standoff = 10\n",
    "    p.yaxis.axis_label_standoff = 10\n",
    "    from bokeh.transform import factor_cmap\n",
    "    index_cmap = factor_cmap('type', palette=['deeppink', 'deepskyblue'], \n",
    "                         factors=sorted(graficos['type'].unique()))\n",
    "    p = figure(plot_width=600, plot_height=450, title = titulo)\n",
    "    p.scatter(columna_x, columna_y, source=source, fill_color=index_cmap, line_color=\"ghostwhite\",size=10,legend='type', alpha=0.8)\n",
    "    p.xaxis.axis_label = columna_x\n",
    "    p.yaxis.axis_label = columna_y\n",
    "    p.legend.location = \"top_left\"\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\")]\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\"),(\"LogP\", \"@LogP\"),(\"MW\", \"@MW\"),(\"NumHAcceptors\", \"@NumHAcceptors\"),(\"NumHDonors\", \"@NumHDonors\"),(\"NumHBondAcceptors\", \"@NumHBondAcceptors\"),(\"NumHBondDonors\", \"@NumHBondDonors\")]\n",
    "    p.add_tools(hover)\n",
    "    p.title.text_font_size = '20pt'\n",
    "    p.title.text_font_style = 'bold'\n",
    "    p.title.align = 'center'\n",
    "    p.xaxis.axis_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.axis_label_text_font_size = '20pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '15pt'\n",
    "    p.yaxis.major_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '15pt'\n",
    "    p.xaxis.major_label_text_font_style = 'bold'\n",
    "    p.axis.axis_line_width = 2\n",
    "    p.axis.major_tick_line_width = 4\n",
    "    show(p)\n",
    "\n",
    "grafico_scatter_bokeh(graficos,'LogP','MW','LogP vs MW','nombre_archivo.html',\"LogP\",\"MW\")\n",
    "#LogP vs MW\n",
    "grafico_scatter_bokeh(graficos,'LogP','NumHAcceptors','LogP vs NumHAcceptors','nombre_archivo.html',\"LogP\",\"NumHAcceptors\")\n",
    "#LogP vs NumHDonors\n",
    "grafico_scatter_bokeh(graficos,'LogP','NumHDonors','LogP vs NumHDonors','nombre_archivo.html',\"LogP\",\"NumHDonors\")\n",
    "#mw \n",
    "grafico_scatter_bokeh(graficos,'MW','NumHAcceptors','MW vs NumHAcceptors','nombre_archivo.html',\"MW\",\"NumHAcceptors\")\n",
    "#mw vs NumHDonors\n",
    "grafico_scatter_bokeh(graficos,'MW','NumHDonors','MW vs NumHDonors','nombre_archivo.html',\"MW\",\"NumHDonors\")\n",
    "#NumHAcceptors vs NumHDonors\n",
    "grafico_scatter_bokeh(graficos,'NumHAcceptors','NumHDonors','NumHAcceptors vs NumHDonors','nombre_archivo.html',\"NumHAcceptors\",\"NumHDonors\")\n",
    "#MW VS NumHBondAcceptors\n",
    "grafico_scatter_bokeh(graficos,'MW','NumHBondAcceptors','MW vs NumHBondAcceptors','nombre_archivo.html',\"MW\",\"NumHBondAcceptors\")\n",
    "#MW VS NumHBondDonors\n",
    "grafico_scatter_bokeh(graficos,'MW','NumHBondDonors','MW vs NumHBondDonors','nombre_archivo.html',\"MW\",\"NumHBondDonors\")\n",
    "#NumHAcceptors VS NumHBondAcceptors\n",
    "grafico_scatter_bokeh(graficos,'NumHAcceptors','NumHBondAcceptors','NumHAcceptors vs NumHBondAcceptors','nombre_archivo.html',\"NumHAcceptors\",\"NumHBondAcceptors\")\n",
    "#PIC50 VS\n",
    "grafico_scatter_bokeh(graficos,'PIC50','LogP','PIC50 vs LogP','nombre_archivo.html',\"PIC50\",\"LogP\")\n",
    "#PIC50 VS MW\n",
    "grafico_scatter_bokeh(graficos,'PIC50','MW','PIC50 vs MW','nombre_archivo.html',\"PIC50\",\"MW\")\n",
    "#PIC50 VS NumHAcceptors\n",
    "grafico_scatter_bokeh(graficos,'PIC50','NumHAcceptors','PIC50 vs NumHAcceptors','nombre_archivo.html',\"PIC50\",\"NumHAcceptors\")\n",
    "#PIC50 VS NumHDonors\n",
    "grafico_scatter_bokeh(graficos,'PIC50','NumHDonors','PIC50 vs NumHDonors','nombre_archivo.html',\"PIC50\",\"NumHDonors\")\n",
    "#PIC50 VS NumHBondAcceptors\n",
    "grafico_scatter_bokeh(graficos,'PIC50','NumHBondAcceptors','PIC50 vs NumHBondAcceptors','nombre_archivo.html',\"PIC50\",\"NumHBondAcceptors\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dinamicos agregar cada punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "#Esta función grafica un gráfico de dispersión utilizando Bokeh. \n",
    "# Los parámetros de entrada son un dataframe, el nombre de la columna de los datos del eje x, \n",
    "# el nombre de la columna de los datos del eje y, el título del gráfico, el nombre del archivo para guardar el gráfico,\n",
    "# el nombre del eje x y el nombre del eje y. Además, permite mostrar una leyenda en la parte superior izquierda de la gráfica \n",
    "# y una descripción de cada punto del gráfico al pasar el mouse sobre el punto.\n",
    "def grafico_scatter_bokeh(df,columna_x,columna_y,titulo,nombre_archivo,nombrex,nombrey):\n",
    "    df=df.sort_values(by=columna_x)\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(plot_width=800, plot_height=400,title=titulo)\n",
    "    p.circle(columna_x, columna_y, source=source, size=10, color=\"blue\", alpha=0.5)\n",
    "    p.xaxis.axis_label = nombrex\n",
    "    p.yaxis.axis_label = nombrey\n",
    "    #text_alpha\n",
    "    p.xaxis.axis_label_text_alpha = 1\n",
    "    p.yaxis.axis_label_text_alpha = 1\n",
    "    #text_font\n",
    "    p.xaxis.axis_label_text_font = \"times\"\n",
    "    p.yaxis.axis_label_text_font = \"times\"\n",
    "    #text_font_size\n",
    "    p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "    #text_font_style\n",
    "    p.xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.yaxis.axis_label_text_font_style = \"bold\"\n",
    "    #calidad de la letra\n",
    "    p.xaxis.axis_label_standoff = 10\n",
    "    p.yaxis.axis_label_standoff = 10\n",
    "    from bokeh.transform import factor_cmap\n",
    "    #index_cmap\n",
    "        \n",
    "    index_cmap = factor_cmap('type', palette=['deeppink', 'deepskyblue'], \n",
    "                         factors=sorted(graficos['type'].unique()))\n",
    "    \n",
    "\n",
    "    #grafico\n",
    "    p = figure(plot_width=600, plot_height=450, title = titulo)\n",
    "    p.scatter(columna_x, columna_y, source=source, fill_color=index_cmap, line_color=\"ghostwhite\",size=10,legend='type', alpha=0.8)\n",
    "    p.xaxis.axis_label = columna_x\n",
    "    p.yaxis.axis_label = columna_y\n",
    "    p.legend.location = \"top_left\"\n",
    "    \n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\")]\n",
    "    #PIC50 AL Hover\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\")]\n",
    "    #todos los datos al hover\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\"),(\"LogP\", \"@LogP\"),(\"MW\", \"@MW\"),(\"NumHAcceptors\", \"@NumHAcceptors\"),(\"NumHDonors\", \"@NumHDonors\"),(\"NumHBondAcceptors\", \"@NumHBondAcceptors\"),(\"NumHBondDonors\", \"@NumHBondDonors\")]\n",
    "    \n",
    "    p.add_tools(hover)\n",
    "    p.title.text_font_size = '20pt'\n",
    "    p.title.text_font_style = 'bold'\n",
    "    #el titulo\n",
    "    p.title.align = 'center'\n",
    "    p.xaxis.axis_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.axis_label_text_font_size = '20pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '15pt'\n",
    "    p.yaxis.major_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '15pt'\n",
    "    p.xaxis.major_label_text_font_style = 'bold'\n",
    "    p.axis.axis_line_width = 2\n",
    "    p.axis.major_tick_line_width = 4\n",
    "    \n",
    "    \n",
    "\n",
    "    show(p)\n",
    "\n",
    "    \n",
    "\n",
    "grafico_scatter_bokeh(graficos,'LogP','MW','LogP vs MW','nombre_archivo.html',\"LogP\",\"MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficos[graficos['molecule_chembl_id']=='CHEMBL4073922']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta función grafico_line_bokeh_color toma como entrada un dataframe \n",
    "# y dos columnas del mismo, y crea un gráfico de dispersión con la columna_x en el eje x \n",
    "# y la columna_y en el eje y. Además, agrega un título al gráfico y le da nombres a los ejes x y y.\n",
    "# También agrega una herramienta de hover que muestra información adicional al pasar el cursor sobre los puntos del gráfico.\n",
    "# Además, el gráfico tiene una línea de tendencia y los puntos están coloreados según una columna del dataframe.\n",
    "# Finalmente, muestra el gráfico utilizando la función show de Bokeh.\n",
    "\n",
    "def grafico_line_bokeh_color(df,columna_x,columna_y,titulo,nombre_archivo,nombrex,nombrey):\n",
    "    df=df.sort_values(by=columna_x)\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(plot_width=800, plot_height=400,title=titulo)\n",
    "    p.line(columna_x, columna_y, source=source, line_width=2, line_alpha=0.6,color=\"blue\",alpha=0.1)\n",
    "    p.circle(columna_x, columna_y, source=source, size=10, color=factor_cmap('type', palette=RdPu[4], factors=graficos['type'].unique()), alpha=1)\n",
    "    p.xaxis.axis_label = nombrex\n",
    "    p.yaxis.axis_label = nombrey\n",
    "    p.xaxis.axis_label_text_alpha = 1\n",
    "    p.yaxis.axis_label_text_alpha = 1\n",
    "    index_cmap = factor_cmap('type', palette=['deeppink', 'deepskyblue'],\n",
    "                            factors=sorted(graficos['type'].unique()))\n",
    "    p = figure(plot_width=600, plot_height=450, title = titulo)\n",
    "    p.line(columna_x, columna_y, source=source, line_width=2, line_alpha=0.6,color=\"gainsboro\",alpha=0.8)\n",
    "    p.circle(columna_x, columna_y, source=source, size=10, color=index_cmap,line_color=\"ghostwhite\",legend='type')    \n",
    "    p.xaxis.axis_label = columna_x\n",
    "    p.yaxis.axis_label = columna_y\n",
    "    p.legend.location = \"top_left\"\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\")]\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\")]\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\"),(\"LogP\", \"@LogP\"),(\"MW\", \"@MW\"),(\"NumHAcceptors\", \"@NumHAcceptors\"),(\"NumHDonors\", \"@NumHDonors\"),(\"NumHBondAcceptors\", \"@NumHBondAcceptors\"),(\"NumHBondDonors\", \"@NumHBondDonors\")]\n",
    "    p.add_tools(hover)\n",
    "    p.title.text_font_size = '20pt'\n",
    "    p.title.text_font_style = 'bold'\n",
    "    p.title.align = 'center'\n",
    "    p.xaxis.axis_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.axis_label_text_font_size = '20pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '15pt'\n",
    "    p.yaxis.major_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '15pt'\n",
    "    p.xaxis.major_label_text_font_style = 'bold'\n",
    "    p.axis.axis_line_width = 2\n",
    "    p.axis.major_tick_line_width = 4\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    show(p)\n",
    "\n",
    "grafico_line_bokeh_color(graficos,'LogP','MW','LogP vs MW','nombre_archivo.html',\"LogP\",\"MW\")\n",
    "#LogP vs\n",
    "grafico_line_bokeh_color(graficos,'LogP','NumHAcceptors','LogP vs NumHAcceptors','nombre_archivo.html',\"LogP\",\"NumHAcceptors\")\n",
    "#LogP vs NumHDonors\n",
    "grafico_line_bokeh_color(graficos,'LogP','NumHDonors','LogP vs NumHDonors','nombre_archivo.html',\"LogP\",\"NumHDonors\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BARRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import CrosshairTool\n",
    "#Barras con bokeh\n",
    "\n",
    "from bokeh.palettes import Plasma\n",
    "def grafico_barra_bokeh_color(df,columna_x,columna_y,titulo,nombre_archivo,nombrex,nombrey):\n",
    "    #df=df.sort_values(by=columna_x)\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(plot_width=800, plot_height=400,title=titulo)\n",
    "    p.vbar(x=columna_x, top=columna_y, source=source, width=0.9, alpha=1, line_color=None, fill_color=factor_cmap('type', palette=RdPu[4], factors=graficos['type'].unique()))\n",
    "    p.xaxis.axis_label = nombrex\n",
    "    p.yaxis.axis_label = nombrey\n",
    "    p.xaxis.axis_label_text_alpha = 1\n",
    "    p.yaxis.axis_label_text_alpha = 1\n",
    "    index_cmap = factor_cmap('type', palette=['deeppink', 'deepskyblue'],\n",
    "                            factors=sorted(graficos['type'].unique()))\n",
    "    p = figure(plot_width=600, plot_height=450, title = titulo)\n",
    "    p.vbar(x=columna_x, top=columna_y, source=source, width=0.9, alpha=1, line_color=None, fill_color=index_cmap,legend='type')\n",
    "    p.xaxis.axis_label = columna_x\n",
    "    p.yaxis.axis_label = columna_y\n",
    "    p.legend.location = \"top_left\"\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\")]\n",
    "\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\")]\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\"),(\"LogP\", \"@LogP\"),(\"MW\", \"@MW\"),(\"NumHAcceptors\", \"@NumHAcceptors\"),(\"NumHDonors\", \"@NumHDonors\"),(\"NumHBondAcceptors\", \"@NumHBondAcceptors\"),(\"NumHBondDonors\", \"@NumHBondDonors\")]\n",
    "    p.add_tools(hover)\n",
    "    p.title.text_font_size = '20pt'\n",
    "    p.title.text_font_style = 'bold'\n",
    "    p.title.align = 'center'\n",
    "    p.xaxis.axis_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.axis_label_text_font_size = '20pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '15pt'\n",
    "    p.yaxis.major_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '15pt'\n",
    "    p.xaxis.major_label_text_font_style = 'bold'\n",
    "    p.axis.axis_line_width = 2\n",
    "    p.axis.major_tick_line_width = 4\n",
    "    show(p)\n",
    "\n",
    "grafico_barra_bokeh_color(graficos,'MW','LogP','LogP vs MW','nombre_archivo.html',\"LogP\",\"MW\")\n",
    "#LogP vs\n",
    "grafico_barra_bokeh_color(graficos,'NumHAcceptors','LogP','LogP vs NumHAcceptors','nombre_archivo.html',\"LogP\",\"NumHAcceptors\")\n",
    "#LogP vs NumHDonors\n",
    "grafico_barra_bokeh_color(graficos,'NumHDonors','LogP','LogP vs NumHDonors','nombre_archivo.html',\"LogP\",\"NumHDonors\")\n",
    "#MW vs\n",
    "grafico_barra_bokeh_color(graficos,'MW','NumHAcceptors','MW vs NumHAcceptors','nombre_archivo.html',\"MW\",\"NumHAcceptors\")\n",
    "#MW vs NumHDonors\n",
    "grafico_barra_bokeh_color(graficos,'MW','NumHDonors','MW vs NumHDonors','nombre_archivo.html',\"MW\",\"NumHDonors\")\n",
    "#NumHAcceptors vs NumHDonors\n",
    "grafico_barra_bokeh_color(graficos,'NumHAcceptors','NumHDonors','NumHAcceptors vs NumHDonors','nombre_archivo.html',\"NumHAcceptors\",\"NumHDonors\")\n",
    "#MW VS PIC50\n",
    "grafico_barra_bokeh_color(graficos,'MW','PIC50','MW vs PIC50','nombre_archivo.html',\"MW\",\"PIC50\")\n",
    "#LogP VS PIC50\n",
    "grafico_barra_bokeh_color(graficos,'LogP','PIC50','LogP vs PIC50','nombre_archivo.html',\"LogP\",\"PIC50\")\n",
    "#NumHAcceptors VS PIC50\n",
    "grafico_barra_bokeh_color(graficos,'NumHAcceptors','PIC50','NumHAcceptors vs PIC50','nombre_archivo.html',\"NumHAcceptors\",\"PIC50\")\n",
    "#NumHDonors VS PIC50\n",
    "grafico_barra_bokeh_color(graficos,'NumHDonors','PIC50','NumHDonors vs PIC50','nombre_archivo.html',\"NumHDonors\",\"PIC50\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HISTOGRAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma con bokeh\n",
    "def histogram_categorical_bokeh(x,data,hue,palette,title,xlabel,ylabel):\n",
    "    p = figure(title=title, background_fill_color=\"#ffffff\")\n",
    "    hist, edges = np.histogram(data[x], density=True, bins=50)\n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "           fill_color=\"deepskyblue\", line_color=\"#033649\",alpha=0.7)\n",
    "    p.xaxis.axis_label = xlabel\n",
    "    p.yaxis.axis_label = ylabel\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\"),(\"LogP\", \"@LogP\"),(\"MW\", \"@MW\"),(\"NumHAcceptors\", \"@NumHAcceptors\"),(\"NumHDonors\", \"@NumHDonors\"),(\"NumHBondAcceptors\", \"@NumHBondAcceptors\"),(\"NumHBondDonors\", \"@NumHBondDonors\")]\n",
    "    p.add_tools(hover)\n",
    "    p.title.text_font_size = '20pt'\n",
    "    p.title.text_font_style = 'bold'\n",
    "    p.title.align = 'center'\n",
    "    p.xaxis.axis_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.axis_label_text_font_size = '20pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '15pt'\n",
    "    p.yaxis.major_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '15pt'\n",
    "    p.xaxis.major_label_text_font_style = 'bold'\n",
    "    p.axis.axis_line_width = 2\n",
    "    p.axis.major_tick_line_width = 4\n",
    "    \n",
    "    show(p)\n",
    "\n",
    "histogram_categorical_bokeh('LogP',graficos,'type',RdPu[4],'LogP','LogP','Probabilidad')\n",
    "histogram_categorical_bokeh('MW',graficos,'type',RdPu[4],'MW','MW','Probabilidad')\n",
    "histogram_categorical_bokeh('NumHAcceptors',graficos,'type',RdPu[4],'NumHAcceptors','NumHAcceptors','Probabilidad')\n",
    "histogram_categorical_bokeh('NumHDonors',graficos,'type',RdPu[4],'NumHDonors','NumHDonors','Probabilidad')\n",
    "histogram_categorical_bokeh('PIC50',graficos,'type',RdPu[4],'PIC50','PIC50','Probabilidad')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_scatter_bokeh_color(data,x,y,titulo,archivo,xlabel,ylabel):\n",
    "    source = ColumnDataSource(data)\n",
    "    index_cmap = factor_cmap('type', palette=RdPu[4], factors=sorted(data.type.unique()))\n",
    "\n",
    "    p = figure(plot_width=600, plot_height=450, title = titulo)\n",
    "    p.line(x=x, y=y, source=source, line_width=2, line_alpha=0.6,)\n",
    "    p.scatter(x=x, y=y, source=source, size=10, alpha=1, line_color=None, fill_color=index_cmap,legend='type')\n",
    "    p.xaxis.axis_label = xlabel\n",
    "    p.yaxis.axis_label = ylabel\n",
    "    p.legend.location = \"top_left\"\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [(\"molecule_chembl_id\", \"@molecule_chembl_id\"),(\"PIC50\", \"@PIC50\"),(\"LogP\",\n",
    "    \"@LogP\"),(\"MW\", \"@MW\"),(\"NumHAcceptors\", \"@NumHAcceptors\"),(\"NumHDonors\", \"@NumHDonors\"),(\"NumHBondAcceptors\", \"@NumHBondAcceptors\"),(\"NumHBondDonors\", \"@NumHBondDonors\")]\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    show(p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHISKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, Whisker\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.sampledata.autompg2 import autompg2 as df\n",
    "from bokeh.transform import factor_cmap, jitter\n",
    "\n",
    "# Whisker con bokeh\n",
    "\n",
    "def grafico_wisker_bokeh(data,x,y,titulo,archivo,xlabel,ylabel):\n",
    "    source = ColumnDataSource(data)\n",
    "    classes = list(sorted(data[\"type\"].unique()))\n",
    "    index_cmap = factor_cmap('type', palette=RdPu[4], factors=sorted(data.type.unique()))\n",
    "    p = figure(plot_width=600, plot_height=450, title = titulo,x_range=classes)\n",
    "    g = data.groupby(\"type\")\n",
    "\n",
    "    upper=[g.get_group(c)[y].max() for c in classes]\n",
    "    lower=[g.get_group(c)[y].min() for c in classes]\n",
    "    middle=[g.get_group(c)[y].mean() for c in classes]\n",
    "    \n",
    "    \n",
    "    p.x_range.range_padding = 5\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis.axis_label = xlabel\n",
    "    p.yaxis.axis_label = ylabel\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.scatter(x=classes, y=upper, size=8, color=\"deeppink\", alpha=1)\n",
    "    p.scatter(x=classes, y=lower, size=8, color=\"deepskyblue\", alpha=1)\n",
    "    p.segment(x0=classes, y0=upper, x1=classes, y1=lower, color=\"mediumslateblue\", line_width=2, line_alpha=0.3)\n",
    "    p.vbar(x=classes, top=middle, width=0.7, line_color=\"magenta\", fill_color=index_cmap,legend='type')\n",
    "    p.legend.location = \"top_left\"\n",
    "    # minimos maximos y medios\n",
    "    print(\"los maximos son: {} \".format(upper))\n",
    "    print(\"los minimos son: {} \".format(lower))\n",
    "    print(\"los medios son: {} \".format(middle))\n",
    "    p.title.text_font_size = '20pt'\n",
    "    p.title.text_font_style = 'bold'\n",
    "    #el titulo\n",
    "    p.title.align = 'center'\n",
    "    p.xaxis.axis_label_text_font_size = '20pt'\n",
    "    p.xaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.axis_label_text_font_size = '20pt'\n",
    "    p.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p.yaxis.major_label_text_font_size = '15pt'\n",
    "    p.yaxis.major_label_text_font_style = 'bold'\n",
    "    p.xaxis.major_label_text_font_size = '15pt'\n",
    "    p.xaxis.major_label_text_font_style = 'bold'\n",
    "    p.axis.axis_line_width = 2\n",
    "    p.axis.major_tick_line_width = 4\n",
    "    show(p)\n",
    "\n",
    "grafico_wisker_bokeh(graficos,'type','LogP','LogP','nombre_archivo.html',\"type\",\"LogP\")\n",
    "grafico_wisker_bokeh(graficos,'type','MW','MW','nombre_archivo.html',\"type\",\"MW\")\n",
    "#type con NumHAcceptors\n",
    "grafico_wisker_bokeh(graficos,'type','NumHAcceptors','NumHAcceptors','nombre_archivo.html',\"type\",\"NumHAcceptors\")\n",
    "#type con NumHDonors\n",
    "grafico_wisker_bokeh(graficos,'type','NumHDonors','NumHDonors','nombre_archivo.html',\"type\",\"NumHDonors\")\n",
    "#type con NumHBondAcceptors\n",
    "grafico_wisker_bokeh(graficos,'type','NumHBondAcceptors','NumHBondAcceptors','nombre_archivo.html',\"type\",\"NumHBondAcceptors\")\n",
    "#type con NumHBondDonors\n",
    "grafico_wisker_bokeh(graficos,'type','NumHBondDonors','NumHBondDonors','nombre_archivo.html',\"type\",\"NumHBondDonors\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORRELACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapa_correlacion(df):\n",
    "    corr = df.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm')\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\")\n",
    "    plt.show()\n",
    "\n",
    "mapa_correlacion(graficos)\n",
    "\n",
    "\n",
    "#lista con los valores del mapa de correlacion\n",
    "def lista_correlacion(df):\n",
    "    corr = df.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm')\n",
    "    print(corr)\n",
    "\n",
    "lista_correlacion(graficos)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO DIMANICOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los siguientes codigos en la seccion NO DINAMICOS crean diferentes tipos de graficos como de línea, scatter, wisker, barras con mathplotlib, seaborn y colores para un conjunto de datos específico (df)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_compare(df, var_cat, var_num, color_cat,labelx,labely,title):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.boxplot(x=var_cat, y=var_num, data=df, palette=color_cat)\n",
    "    plt.xlabel(labelx, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(labely, fontsize=14, fontweight='bold')\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.setp(plt.gca().artists, edgecolor = 'k', facecolor='w')\n",
    "    plt.setp(plt.gca().lines, color='k')\n",
    "    plt.show()\n",
    "boxplot_compare(graficos,'type','LogP',['palevioletred', 'lightskyblue'],\"type\",\"LogP\",\"LogP vs type\")\n",
    "boxplot_compare(graficos,'type','MW',['palevioletred', 'lightskyblue'],\"type\",\"MW\",\"MW vs type\")\n",
    "boxplot_compare(graficos,'type','NumHDonors',['palevioletred', 'lightskyblue'],\"type\",\"NumHDonors\",\"NumHDonorsvs type\")\n",
    "boxplot_compare(graficos,'type','NumHAcceptors',['palevioletred', 'lightskyblue'],\"type\",\"NumHAcceptors\",\"NumHAcceptors vs type\")\n",
    "boxplot_compare(graficos,'type','NumHBondAcceptors',['palevioletred', 'lightskyblue'],\"type\",\"NumHBondAcceptors\",\"NumHBondAcceptors vs type\")\n",
    "boxplot_compare(graficos,'type','PIC50',['palevioletred', 'lightskyblue'],\"type\",\"PIC50\",\"PIC50 vs type\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_categorical(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(50, 50), dpi=160)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.lmplot(x=x, y=y, data=data, hue=hue, palette=palette, size=6,aspect=2,fit_reg=False)\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc='upper right', fontsize=20)\n",
    "    plt.show()\n",
    "scatterplot_categorical('LogP','MW',graficos,'type',['palevioletred', 'lightskyblue'],\"LogP vs MW\",\"LogP\",\"MW\")\n",
    "scatterplot_categorical('LogP','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],\"LogP vs NumHDonors\",\"LogP\",\"NumHDonors\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_hue(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.pointplot(x=x, y=y, hue=hue, data=data, palette=palette,alpha=0.7,edgecolor='black', pointkws={\"linestyle\":\"-\",\"linewidth\":0.4,\"marker\":\"o\",\"markersize\":2,\"alpha\":0.5},linekws={\"linewidth\":0.5,\"alpha\":0.5},size=6,aspect=2,point_size=0.5)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 3 , facecolor=\"w\", fontsize=16)\n",
    "    #ticks\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "lineplot_hue('LogP','MW',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','MW')\n",
    "lineplot_hue('LogP','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','NumHDonors')\n",
    "lineplot_hue('LogP','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','NumHAcceptors')\n",
    "lineplot_hue('LogP','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','NumHBondAcceptors')\n",
    "lineplot_hue('MW','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','MW','NumHDonors')\n",
    "lineplot_hue('MW','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','MW','NumHAcceptors')\n",
    "lineplot_hue('MW','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','MW','NumHBondAcceptors')\n",
    "lineplot_hue('NumHDonors','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','NumHDonors','NumHAcceptors')\n",
    "lineplot_hue('NumHDonors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','NumHDonors','NumHBondAcceptors')\n",
    "lineplot_hue('NumHAcceptors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','NumHAcceptors','NumHBondAcceptors')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BARPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_categorical_stacked_percent_hue(x,y,data,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.barplot(x=x, y=y, data=data, palette=palette, hue_order=[\"0\", \"1\"], dodge=False,edgecolor='black',)\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.setp(plt.gca().artists, edgecolor = 'k', facecolor='w')\n",
    "    plt.setp(plt.gca().lines, color='k')\n",
    "    plt.xlabel(xlabel, fontsize=10, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=10, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "barplot_categorical_stacked_percent_hue('type','LogP',graficos,['palevioletred', 'lightskyblue'],'Barplot','type','LogP')\n",
    "barplot_categorical_stacked_percent_hue('type','MW',graficos,['palevioletred', 'lightskyblue'],'Barplot','type','MW')\n",
    "barplot_categorical_stacked_percent_hue('type','NumHDonors',graficos,['palevioletred', 'lightskyblue'],'Barplot','type','NumHDonors')\n",
    "barplot_categorical_stacked_percent_hue('type','NumHAcceptors',graficos,['palevioletred', 'lightskyblue'],'Barplot','type','NumHAcceptors')\n",
    "barplot_categorical_stacked_percent_hue('type','NumHBondAcceptors',graficos,['palevioletred', 'lightskyblue'],'Barplot','type','NumHBondAcceptors')\n",
    "#pic50 VS tYPE\n",
    "barplot_categorical_stacked_percent_hue('type','PIC50',graficos,['palevioletred', 'lightskyblue'],'Barplot','type','pic50')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HISTOGRAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histplot_hue(x,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(8, 8), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.histplot(x=x, hue=hue, data=data, palette=palette, kde=False,edgecolor='black',alpha=0.7)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "histplot_hue('LogP',graficos,'type',['palevioletred', 'lightskyblue'],'Histogram','LogP','Count')\n",
    "histplot_hue('MW',graficos,'type',['palevioletred', 'lightskyblue'],'Histogram','MW','Count')\n",
    "histplot_hue('NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Histogram','NumHDonors','Count')\n",
    "histplot_hue('NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Histogram','NumHAcceptors','Count')\n",
    "histplot_hue('NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Histogram','NumHBondAcceptors','Count')\n",
    "#PIC50\n",
    "histplot_hue('PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'Histogram','PIC50','Count')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_categorical(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(8, 8), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.lineplot(x=x, y=y, hue=hue, data=data, palette=palette,alpha=1)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "lineplot_categorical('LogP','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','NumHAcceptors')\n",
    "lineplot_categorical('LogP','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','NumHDonors')\n",
    "lineplot_categorical('LogP','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','LogP','NumHBondAcceptors')\n",
    "lineplot_categorical('MW','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','MW','NumHAcceptors')\n",
    "lineplot_categorical('MW','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','MW','NumHDonors')\n",
    "lineplot_categorical('MW','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','MW','NumHBondAcceptors')\n",
    "lineplot_categorical('NumHAcceptors','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','NumHAcceptors','NumHDonors')\n",
    "lineplot_categorical('NumHAcceptors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','NumHAcceptors','NumHBondAcceptors')\n",
    "lineplot_categorical('NumHDonors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Lineplot','NumHDonors','NumHBondAcceptors')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDEPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kdeplot\n",
    "def kdeplot_hue(x,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.kdeplot(x=x, hue=hue, data=data, palette=palette,alpha=0.7)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "    #plt.legend(graficos[\"type\"],loc= 1 , fontsize=16)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "kdeplot_hue('LogP',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','LogP','Count')\n",
    "kdeplot_hue('MW',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','MW','Count')\n",
    "kdeplot_hue('NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHDonors','Count')\n",
    "kdeplot_hue('NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHAcceptors','Count')\n",
    "kdeplot_hue('NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHBondAcceptors','Count')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HISTOGRAMA CON KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displot_categorical(x,data,palette,title,xlabel,ylabel):\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    " \n",
    "    sns.distplot(data[x], bins=10, kde=True, rug=True,color=palette[1],hist_kws={'alpha':1,'edgecolor':'black','linewidth': 2},kde_kws={'color':'black','linewidth': 4},rug_kws={'color': 'green','alpha':0})\n",
    "\n",
    "\n",
    "    \n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=10, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=10, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=1)\n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "    \n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "displot_categorical('LogP',graficos,['palevioletred', 'lightskyblue'],'Histogram','LogP','Count')\n",
    "displot_categorical('MW',graficos,['palevioletred', 'lightskyblue'],'Histogram','MW','Count')\n",
    "displot_categorical('NumHDonors',graficos,['palevioletred', 'lightskyblue'],'Histogram','NumHDonors','Count')\n",
    "displot_categorical('NumHAcceptors',graficos,['palevioletred', 'lightskyblue'],'Histogram','NumHAcceptors','Count')\n",
    "displot_categorical('NumHBondAcceptors',graficos,['palevioletred', 'lightskyblue'],'Histogram','NumHBondAcceptors','Count')\n",
    "#PIC50\n",
    "displot_categorical('PIC50',graficos,['palevioletred', 'lightskyblue'],'Histogram','PIC50','Count')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BARPLOT GRUUPBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BARRAS CON GRUOUPBY Y HUE\n",
    "def barplot_hue(x,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.barplot(x=x, y=\"count\", hue=hue, data=data, palette=palette)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "barplot_hue('NumHDonors',graficos.groupby(['NumHDonors','type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','NumHDonors','Count')\n",
    "barplot_hue('NumHAcceptors',graficos.groupby(['NumHAcceptors','type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','NumHAcceptors','Count')\n",
    "barplot_hue('NumHBondAcceptors',graficos.groupby(['NumHBondAcceptors','type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','NumHBondAcceptors','Count')\n",
    "#TYPE\n",
    "barplot_hue('type',graficos.groupby(['type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','type','Count')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCATTERPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SCATTERPLOT\n",
    "def scatterplot_hue(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.scatterplot(x=x, y=y, hue=hue, data=data, palette=palette)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "scatterplot_hue('LogP','MW',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','MW')\n",
    "scatterplot_hue('NumHDonors','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHDonors','NumHAcceptors')\n",
    "scatterplot_hue('NumHDonors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHDonors','NumHBondAcceptors')\n",
    "scatterplot_hue('NumHAcceptors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHAcceptors','NumHBondAcceptors')\n",
    "scatterplot_hue('LogP','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','NumHDonors')\n",
    "scatterplot_hue('LogP','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','NumHAcceptors')\n",
    "scatterplot_hue('LogP','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','NumHBondAcceptors')\n",
    "scatterplot_hue('MW','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','MW','NumHDonors')\n",
    "scatterplot_hue('MW','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','MW','NumHAcceptors')\n",
    "scatterplot_hue('MW','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','MW','NumHBondAcceptors')\n",
    "scatterplot_hue('NumHDonors','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHDonors','NumHAcceptors')\n",
    "scatterplot_hue('NumHDonors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHDonors','NumHBondAcceptors')\n",
    "scatterplot_hue('NumHAcceptors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHAcceptors','NumHBondAcceptors')\n",
    "scatterplot_hue('LogP','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','NumHDonors')\n",
    "#LOGP vs pic50\n",
    "scatterplot_hue('LogP','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','PIC50')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METODO DISPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displot con hue y groupby\n",
    "def displot_hue(x,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(8, 8), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.distplot(data[x], bins=10, kde=True, rug=True,color=palette[1],hist_kws={'alpha':0.5,'edgecolor':'black','linewidth': 2},kde_kws={'color':'black','linewidth': 4},rug_kws={'color': 'green','alpha': 0})\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "displot_hue('LogP',graficos,'type',['palevioletred', 'lightskyblue'],'Displot','LogP','Count')\n",
    "displot_hue('MW',graficos,'type',['palevioletred', 'lightskyblue'],'Displot','MW','Count')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdeplot_shade(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.kdeplot(data[x], data[y], shade=True, cmap='Reds')\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "kdeplot_shade('LogP','MW',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','LogP','MW')\n",
    "kdeplot_shade('LogP','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','LogP','NumHDonors')\n",
    "kdeplot_shade('LogP','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','LogP','NumHAcceptors')\n",
    "kdeplot_shade('LogP','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','LogP','NumHBondAcceptors')\n",
    "kdeplot_shade('LogP','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','LogP','PIC50')\n",
    "kdeplot_shade('MW','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','MW','NumHDonors')\n",
    "kdeplot_shade('MW','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','MW','NumHAcceptors')\n",
    "kdeplot_shade('MW','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','MW','NumHBondAcceptors')\n",
    "kdeplot_shade('MW','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','MW','PIC50')\n",
    "kdeplot_shade('NumHDonors','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHDonors','NumHAcceptors')\n",
    "kdeplot_shade('NumHDonors','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHDonors','NumHBondAcceptors')\n",
    "kdeplot_shade('NumHDonors','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHDonors','PIC50')\n",
    "kdeplot_shade('NumHAcceptors','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHAcceptors','PIC50')\n",
    "kdeplot_shade('NumHBondAcceptors','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'KDE','NumHBondAcceptors','PIC50')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIOLIN PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violin_numeric(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.violinplot(x=x, y=y, hue=hue, data=data, palette=palette, split=True, inner=\"quart\")\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "violin_numeric('type','LogP',graficos,'type',['palevioletred', 'lightskyblue'],'Violin','type','LogP')\n",
    "violin_numeric('type','MW',graficos,'type',['palevioletred', 'lightskyblue'],'Violin','type','MW')\n",
    "violin_numeric('type','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Violin','type','NumHDonors')\n",
    "violin_numeric('type','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Violin','type','NumHAcceptors')\n",
    "violin_numeric('type','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Violin','type','NumHBondAcceptors')\n",
    "violin_numeric('type','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'Violin','type','PIC50')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOINPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jointplot con hue\n",
    "def jointplot_hue(x,y,data,hue,color,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(8, 8), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.jointplot(x=x, y=y, data=data, kind=\"kde\", color=color, height=7)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "jointplot_hue('LogP','MW',graficos,'type','palevioletred','Jointplot','LogP','MW')\n",
    "jointplot_hue('LogP','NumHDonors',graficos,'type','palevioletred','Jointplot','LogP','NumHDonors')\n",
    "jointplot_hue('LogP','NumHAcceptors',graficos,'type','palevioletred','Jointplot','LogP','NumHAcceptors')\n",
    "jointplot_hue('LogP','NumHBondAcceptors',graficos,'type','palevioletred','Jointplot','LogP','NumHBondAcceptors')\n",
    "jointplot_hue('LogP','PIC50',graficos,'type','palevioletred','Jointplot','LogP','PIC50')\n",
    "jointplot_hue('MW','NumHDonors',graficos,'type','palevioletred','Jointplot','MW','NumHDonors')\n",
    "jointplot_hue('MW','NumHAcceptors',graficos,'type','palevioletred','Jointplot','MW','NumHAcceptors')\n",
    "jointplot_hue('MW','NumHBondAcceptors',graficos,'type','palevioletred','Jointplot','MW','NumHBondAcceptors')\n",
    "jointplot_hue('MW','PIC50',graficos,'type','palevioletred','Jointplot','MW','PIC50')\n",
    "jointplot_hue('NumHDonors','NumHAcceptors',graficos,'type','palevioletred','Jointplot','NumHDonors','NumHAcceptors')\n",
    "jointplot_hue('NumHDonors','NumHBondAcceptors',graficos,'type','palevioletred','Jointplot','NumHDonors','NumHBondAcceptors')\n",
    "jointplot_hue('NumHDonors','PIC50',graficos,'type','palevioletred','Jointplot','NumHDonors','PIC50')\n",
    "jointplot_hue('NumHAcceptors','PIC50',graficos,'type','palevioletred','Jointplot','NumHAcceptors','PIC50')\n",
    "jointplot_hue('NumHBondAcceptors','PIC50',graficos,'type','palevioletred','Jointplot','NumHBondAcceptors','PIC50')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRIPPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot_numeric(x,y,data,hue,palette,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(5, 5), dpi=160)\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.stripplot(x=x, y=y, hue=hue, data=data, palette=palette, jitter=True)\n",
    "    plt.title(title, fontsize=20, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    plt.legend(loc= 1 , facecolor=\"w\", fontsize=16)\n",
    "    plt.xticks(fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=10, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "stripplot_numeric('type','LogP',graficos,'type',['palevioletred', 'lightskyblue'],'Stripplot','type','LogP')\n",
    "stripplot_numeric('type','MW',graficos,'type',['palevioletred', 'lightskyblue'],'Stripplot','type','MW')\n",
    "stripplot_numeric('type','NumHDonors',graficos,'type',['palevioletred', 'lightskyblue'],'Stripplot','type','NumHDonors')\n",
    "stripplot_numeric('type','NumHAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Stripplot','type','NumHAcceptors')\n",
    "stripplot_numeric('type','NumHBondAcceptors',graficos,'type',['palevioletred', 'lightskyblue'],'Stripplot','type','NumHBondAcceptors')\n",
    "stripplot_numeric('type','PIC50',graficos,'type',['palevioletred', 'lightskyblue'],'Stripplot','type','PIC50')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EQUILIBRAR LA DATA (Balanceo de datos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este código realiza una técnica de muestreo llamada SMOTE (Synthetic Minority Over-sampling Technique) para manejar el desequilibrio de clases en los datos. Esta técnica genera nuevos ejemplos sintéticos para la clase minoritaria a partir de los ejemplos existentes. El código toma los datos X y y, así como el parámetro ignore, que especifica qué atributos ignorar durante el muestreo. Luego, se aplica SMOTE para generar nuevos ejemplos sintéticos. Los resultados se devuelven como X_resampled y y_resampled. Después de eso, se crea un DataFrame con los resultados del muestreo y se agrega la columna 'type'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se elimina la columna 'type_num' del dataframe graficos\n",
    "#El resultado se almacena en el mismo dataframe graficos.\n",
    "graficos = graficos.drop(columns=['type_num'])\n",
    "graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = graficos \n",
    "resample.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instala imblearn\n",
    "#!pip install -U imbalanced-learn==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample['molecule_chembl_id_num'] = resample['molecule_chembl_id'].str.extract('(\\d+)').astype(int)\n",
    "resample = resample.drop(columns=['molecule_chembl_id'])\n",
    "resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_ignore(X, y, ignore):\n",
    "    sm = SMOTE(random_state=0, k_neighbors=1, sampling_strategy='auto', n_jobs=-1)\n",
    "    X_resampled, y_resampled = sm.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "X_resampled, y_resampled = smote_ignore(resample.drop('type', axis=1), resample['type'], 'molecule_chembl_id')\n",
    "resample = pd.DataFrame(X_resampled, columns=resample.drop('type', axis=1).columns)\n",
    "resample['type'] = y_resampled\n",
    "\n",
    "barplot_hue('type',resample.groupby(['type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','type','Count')\n",
    "\n",
    "resample.groupby(['type']).size().reset_index(name='count')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smote(X, y):\n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_resampled, y_resampled = sm.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample['molecule_chembl_id'] = 'CHEMBL' + resample['molecule_chembl_id_num'].astype(str)\n",
    "resample['molecule_chembl_id'][660:] = 0\n",
    "resample = resample.drop('molecule_chembl_id_num', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample['molecule_chembl_id'] = resample['molecule_chembl_id'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_hue('LogP','MW',resample,'type',['palevioletred', 'lightskyblue'],'Scatterplot','LogP','MW')\n",
    "#barras LogP vs numofaceptator \n",
    "grafico_barra_bokeh_color(resample,'NumHAcceptors','LogP','LogP vs NumHAcceptors','nombre_archivo.html',\"LogP\",\"NumHAcceptors\")\n",
    "#logP numhdonors\n",
    "grafico_barra_bokeh_color(resample,'NumHDonors','LogP','LogP vs NumHDonors','nombre_archivo.html',\"LogP\",\"NumHDonors\")\n",
    "barplot_hue('NumHAcceptors',resample.groupby(['NumHAcceptors','type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','NumHAcceptors','Count')\n",
    "#numaceptators vs logp scatter\n",
    "scatterplot_hue('NumHAcceptors','LogP',resample,'type',['palevioletred', 'lightskyblue'],'Scatterplot','NumHAcceptors','LogP')\n",
    "grafico_scatter_bokeh(resample,'LogP','NumHAcceptors','LogP vs NumHAcceptors','nombre_archivo.html',\"LogP\",\"NumHAcceptors\")\n",
    "grafico_scatter_bokeh(resample,'LogP','NumHDonors','LogP vs NumHDonors','nombre_archivo.html',\"LogP\",\"NumHDonors\")\n",
    "grafico_scatter_bokeh(resample,'LogP','MW','LogP vs MW','nombre_archivo.html',\"LogP\",\"MW\")\n",
    "grafico_scatter_bokeh(resample,'NumHAcceptors','NumHDonors','NumHAcceptors vs NumHDonors','nombre_archivo.html',\"NumHAcceptors\",\"NumHDonors\")\n",
    "grafico_scatter_bokeh(resample,'NumHAcceptors','MW','NumHAcceptors vs MW','nombre_archivo.html',\"NumHAcceptors\",\"MW\")\n",
    "grafico_scatter_bokeh(resample,'NumHDonors','MW','NumHDonors vs MW','nombre_archivo.html',\"NumHDonors\",\"MW\")\n",
    "grafico_scatter_bokeh(resample,'LogP','PIC50','LogP vs PIC50','nombre_archivo.html',\"LogP\",\"PIC50\")\n",
    "grafico_scatter_bokeh(resample,'MW','PIC50','MW vs PIC50','nombre_archivo.html',\"MW\",\"PIC50\")\n",
    "grafico_scatter_bokeh(resample,'NumHAcceptors','PIC50','NumHAcceptors vs PIC50','nombre_archivo.html',\"NumHAcceptors\",\"PIC50\")\n",
    "grafico_scatter_bokeh(resample,'NumHDonors','PIC50','NumHDonors vs PIC50','nombre_archivo.html',\"NumHDonors\",\"PIC50\")\n",
    "grafico_barra_bokeh_color(resample,'PIC50','LogP','LogP vs PIC50','nombre_archivo.html',\"LogP\",\"PIC50\")\n",
    "grafico_barra_bokeh_color(resample,'MW','PIC50','MW vs PIC50','nombre_archivo.html',\"MW\",\"PIC50\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PADEL DESCRIPTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código usa la biblioteca urllib.request para descargar dos archivos desde un repositorio de GitHub. El primer archivo descargado es \"padel.zip\" y el segundo es \"padel.sh\". \n",
    "# Estos archivos se guardan en el directorio actual con los nombres especificados\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip\", \"padel.zip\")\n",
    "urllib.request.urlretrieve(\"https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh\", \"padel.sh\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código importa la biblioteca zipfile y extrae todos los archivos\n",
    "# de un archivo zip llamado \"padel.zip\". Esto significa que todos los archivos\n",
    "# contenidos en el archivo zip se descomprimirán en el directorio actual.\n",
    "import zipfile\n",
    "with zipfile.ZipFile('padel.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código selecciona dos columnas de un marco de datos (df3_class) llamado 'canonical_smiles' y \n",
    "# 'molecule_chembl_id' y luego guarda esas columnas en un archivo de texto llamado 'molecule.smi'. \n",
    "# El archivo se separa con tabulaciones y no contiene encabezados.\n",
    "# Finalmente, el código muestra los primeros 100 registros del marco de datos df3_selection.\n",
    "\n",
    "selection = ['canonical_smiles','molecule_chembl_id']\n",
    "df3_selection = df3_class[selection]\n",
    "df3_selection.to_csv('molecule.smi', sep='\\t', index=False, header=False)\n",
    "df3_selection.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3_selection a excel\n",
    "#df3_selection.to_excel(\"molecule.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código abre un archivo llamado 'molecule.smi' y luego lee todas las líneas del archivo. \n",
    "# Después, imprime las primeras cinco líneas del archivo.\n",
    "with open(\"molecule.smi\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:5]:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código abre el archivo \"molecule.smi\" y lee todas las líneas del archivo. \n",
    "# Luego, cuenta el número de líneas en el archivo y lo imprime en la pantalla.\n",
    "with open(\"molecule.smi\") as f:\n",
    "    lines = f.readlines()\n",
    "    num_lines = len(lines)\n",
    "    print(num_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código abre el archivo \"padel.sh\" y lee todas las líneas del archivo. Luego, imprime \n",
    "# cada línea del archivo en la pantalla. \n",
    "with open(\"padel.sh\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código importa la biblioteca OS de Python, \n",
    "# luego cambia los permisos del archivo padel.sh a 777, \n",
    "# luego obtiene el directorio actual y agrega el directorio de Git a la variable de entorno PATH.\n",
    "# Finalmente, ejecuta el archivo padel.sh y guarda la salida en un archivo log.txt, luego \n",
    "# imprime el contenido del archivo log.txt.\n",
    "import os\n",
    "os.chmod('padel.sh', 0o777)\n",
    "os.getcwd()\n",
    "import os\n",
    "os.environ['PATH'] += os.pathsep + 'C:/Program Files/Git/usr/bin'\n",
    "!bash padel.sh > log.txt\n",
    "!cat log.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código lee un archivo CSV llamado descriptors_output.csv y lo almacena en una variable llamada df3_X. \n",
    "# El archivo CSV contiene datos que se pueden usar para crear una tabla de datos en formato Pandas.\n",
    "df3_X = pd.read_csv('descriptors_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra df3_X\n",
    "df3_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es una variable que contiene los valores de la columna 'PIC50' y \n",
    "# 'type' del marco de datos df3_class. Esta variable \n",
    "# se utiliza para almacenar los valores de ambas columnas en un solo lugar para su uso posterior.\n",
    "df3_Y = df3_class['PIC50']\n",
    "df3_Y = pd.concat([df3_Y, df3_class['type']], axis=1)\n",
    "df3_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es una variable que contiene el resultado de la concatenación de dos dataframes, \n",
    "# df3_X y df3_Y. La concatenación se realiza a lo largo del eje 1 (axis=1), lo que significa que \n",
    "# los dataframes se unen por columnas. \n",
    "# Esto significa que el resultado será un dataframe con todas las columnas de df3_X y df3_Y.\n",
    "dataset3 = pd.concat([df3_X,df3_Y], axis=1)\n",
    "dataset3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLUMNAS IMPORTANTES ANTES DEL BALANCEO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agregando valor numerico a type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código toma un conjunto de datos llamado dataset3 y crea una nueva columna llamada 'type1'.\n",
    "# Esta columna contiene un valor de 1 si la columna 'type' contiene el valor 'IC50', o 2 si no lo es.\n",
    "# Después, elimina las columnas 'type', 'Name', 'PIC50' y 'SMILES'.\n",
    "# Esto reduce el conjunto de datos a solo los datos relevantes para el análisis.\n",
    "importantesAntes = dataset3\n",
    "importantesAntes['type1'] = importantesAntes['type'].apply(lambda x: 1 if x == 'IC50' else 2)\n",
    "importantesAntes.drop(['type'], axis=1, inplace=True)\n",
    "importantesAntes.drop(['Name'], axis=1, inplace=True)\n",
    "importantesAntes.drop(['PIC50'], axis=1, inplace=True)\n",
    "importantesAntes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.to_excel(\"dataset3antes1.xlsx\")\n",
    "#dataset3 = pd.read_excel('dataset3antes1.xlsx')\n",
    "#dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = dataset3.drop(['type1'], axis=1)\n",
    "y = dataset3['type1']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, stratify=y)\n",
    "\n",
    "clf = RidgeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = clf.decision_function(X_test)\n",
    "y_pred_proba = 1 / (1 + np.exp(-y_pred_proba))\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC (Ridge Classifier): {:.4f}\".format(auc))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa y muestra las librerias necesarias para Pycaret.\n",
    "#instala imblearn 0.7.0\n",
    "#instala pycaret 2.3.1\n",
    "#instala sklearn 0.24.1\n",
    "\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "import pycaret\n",
    "print(pycaret.__version__)\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla compare_models(Accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El código siguiente se utiliza para realizar un análisis de clasificación para el conjunto de datos \"dataset3\". El objetivo es predecir la variable \"tipo1\" y se establece un tamaño de entrenamiento del 75%. La división de datos se realiza con estratificación y se habilita la GPU. El proceso se realiza en silencio, con la selección de características habilitada y sin verbose. El ID de sesión es 123 y la normalización está habilitada. Por último, el código invoca el método compare_models() para comparar los modelos entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "s = setup(dataset3, target = 'type1', train_size=0.75, data_split_stratify=True,use_gpu=True,silent=True, feature_selection=True,verbose=False,session_id=123,normalize=True)\n",
    "compare_models()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tan importante es minimizar la tasa de falsos negativos o falsos positivos? La precisión y el recall pueden ser útiles para evaluar esto.\n",
    "\n",
    "¿Hay un desequilibrio significativo en el número de ejemplos de cada clase? Si es así, el MCC puede ser útil ya que es sensible al desequilibrio de clases.\n",
    "\n",
    "¿Estás más interesado en la capacidad del modelo para distinguir entre las dos clases o en su capacidad para hacer predicciones correctas en general? El AUC y la precisión pueden ser útiles para evaluar la primera pregunta, mientras que la precisión y el F1 pueden ser útiles para evaluar la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código es una función que evalúa un modelo de clasificación de PyCaret.\n",
    "# Esta función toma como parámetro el nombre del modelo y los datos.\n",
    "# La función inicializa el entorno de PyCaret, crea el modelo, hace predicciones\n",
    "# con el modelo, sintoniza el modelo, evalúa el rendimiento del modelo \n",
    "# y obtiene la importancia de  las características. \n",
    "# Esta información se almacena en listas globales para su uso posterior.\n",
    "\n",
    "from pycaret.classification import *\n",
    "important_features_list = []\n",
    "result_list = []\n",
    "tuned_models_list = []\n",
    "predictions_list = []\n",
    "results_list = []\n",
    "\n",
    "def eval_model(model_name,datos):   \n",
    "    # Inicializar el entorno de PyCaret\n",
    "    exp_clf1 = setup(data = datos, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True)\n",
    "    set_config('seed', 123)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Hacer predicciones con el modelo\n",
    "    predictions = predict_model(best)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='F1')\n",
    "    #tuned_model = tune_model(best)\n",
    "    tuned_models_list.append(tuned_model)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    result = pull()\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # Obtener la importancia de las características\n",
    "    columns = get_config('X_train').columns\n",
    "    importances = tuned_model.feature_importances_\n",
    "    important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "    important_features_list.append(important_features)\n",
    "    globals()[model_name] = tuned_model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código es una función que se utiliza para evaluar un modelo de clasificación. \n",
    "# Utiliza la biblioteca PyCaret para crear el modelo, sintonizarlo y evaluar su rendimiento. \n",
    "# También calcula las características más importantes del modelo y las agrega a una lista.\n",
    "\n",
    "from pycaret.classification import *\n",
    "# Importar la función permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#feature_names list\n",
    "df_list = []\n",
    "important_features_list = []\n",
    "\n",
    "# Importar la función permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#feature_names list\n",
    "df_list = []\n",
    "\n",
    "def eval_model2(model_name, df):\n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    resultado = pull()\n",
    "    result_list.append(resultado)\n",
    "    \n",
    "    if hasattr(tuned_model, 'feature_importances_'):\n",
    "        columns = df.columns\n",
    "        importances = tuned_model.feature_importances_\n",
    "        important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "        important_features_list.append(important_features)\n",
    "        globals()[model_name] = tuned_model\n",
    "        \n",
    "    elif hasattr(tuned_model, 'coef_'):\n",
    "        coef = tuned_model.coef_[0]\n",
    "        feature_names = list(df.columns)\n",
    "        feature_importances = dict(zip(feature_names, coef))\n",
    "        df2 = pd.DataFrame.from_dict(feature_importances, orient='index', columns=['importance'])        \n",
    "        df2 = df2.sort_values(by='importance', ascending=False)\n",
    "        df2['Model'] = model_name\n",
    "        df_list.append(df2)\n",
    "    if df_list:\n",
    "        result = pd.concat(df_list)\n",
    "        result = result[result['importance'] != 0]\n",
    "        #agregalos a la lista\n",
    "        #important_features_list.append(result)\n",
    "    else:\n",
    "        result = pd.DataFrame()\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código se utiliza para mostrar las características importantes de un modelo de aprendizaje automático.\n",
    "# La primera función, show_important_features(), concatena una lista de características importantes y \n",
    "# las ordena en orden descendente por importancia. \n",
    "# La segunda función, show_important_features2(), busca un modelo específico en la lista de características\n",
    "# importantes y devuelve sus características más importantes.\n",
    "\n",
    "def show_important_features():\n",
    "    important_features_all = pd.concat(important_features_list)   \n",
    "    important_features_all.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    important_features_all['Model'].value_counts()\n",
    "    important_features_all = important_features_all[important_features_all['importance'] != 0]\n",
    "    return important_features_all\n",
    "\n",
    "def show_important_features2(model_name):\n",
    "    important_features_all = None\n",
    "    for features in important_features_list:\n",
    "        if features['Model'].iloc[0] == model_name:\n",
    "            important_features_all = features\n",
    "            break\n",
    "    if important_features_all is None:\n",
    "        print(f\"No se encontraron características importantes para el modelo {model_name}\")\n",
    "    else:\n",
    "        important_features_all.sort_values(by='importance', ascending=False, inplace=True)\n",
    "        important_features_all = important_features_all[important_features_all['importance'] != 0]\n",
    "        return important_features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código realiza una serie de operaciones para mostrar \n",
    "# los resultados finales de una tabla de datos. La primera función, show_common_features(), busca \n",
    "# las características comunes en el conjunto de datos y las devuelve en un marco de datos. \n",
    "# La segunda función, show_total_importance(), agrega la importancia total para cada característica y la\n",
    "# devuelve ordenada por importancia. La tercera función, show_pivot_table(), crea una tabla pivot con la \n",
    "# importancia total para cada modelo y cuenta el número de veces que aparece cada característica.\n",
    "# Finalmente, la última función, show_final_result(), suma todas las importancias para cada característica\n",
    "# y devuelve los resultados ordenados por importancia.\n",
    "def show_common_features(df):\n",
    "    counts = df.groupby('feature')['feature'].count()\n",
    "    common_features = counts[counts > 1]\n",
    "    common_features = pd.DataFrame(common_features)\n",
    "    return common_features\n",
    "def show_total_importance(df):\n",
    "    Resto = df.groupby('feature')['importance'].sum()\n",
    "    Resto = Resto.sort_values(ascending=False)\n",
    "    Resto = pd.DataFrame(Resto)\n",
    "    return Resto\n",
    "def show_pivot_table(df):\n",
    "    result = df.pivot_table(index='feature', columns='Model', values='importance', aggfunc='sum')\n",
    "    counts = df['feature'].value_counts().reset_index()\n",
    "    counts.columns = ['feature', 'count']\n",
    "    result = pd.merge(result, counts, on='feature')\n",
    "    result = result.fillna(0)\n",
    "    result = result[result['count'] > 1]\n",
    "    result = result.sort_values(by='count', ascending=False)\n",
    "    return result\n",
    "\n",
    "def show_final_result(df):\n",
    "    df['importance'] = df['catboost'] + df['gbc'] + df['dt']+df['ada']+df['et']+df['xgboost']+df['rf']+df['lightgbm']+df['svm']+df['lr']+df['lda']+df['ridge']\n",
    "    df = df.sort_values(by='importance', ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código define una función llamada df1 que toma dos parámetros:model_name y indice.\n",
    "# Esta función devuelve un DataFrame. La función primero obtiene el undécimo elemento de \n",
    "# la lista result_list en la posición indicada por el índice. Luego, crea un DataFrame a partir\n",
    "# de ese elemento y agrega una columna llamada Model con el nombre del modelo. \n",
    "# Finalmente, devuelve el DataFrame transpuesto.\n",
    "def df1(model_name,indice):\n",
    "    df1 = result_list[indice].iloc[10]\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1['Model'] = model_name\n",
    "    df1 = df1.T\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código define una función llamada obtener_importancias, que toma \n",
    "# como parámetros un dataframe (df) y un nombre de modelo (model_name). \n",
    "# La función agrega una columna al dataframe llamada \"Model\" que contiene el nombre del modelo. \n",
    "# Si el dataframe no tiene una columna llamada \"index\", se creará una y se renombrará como \"feature\".\n",
    "# Luego, el dataframe se ordenará por la columna \"importance\" en orden descendente. \n",
    "# Se eliminarán las filas duplicadas de la columna \"feature\", manteniendo solo la primera aparición.\n",
    "# Finalmente, se filtrarán las filas cuyo valor en la columna \"importance\" sea mayor a 0. \n",
    "# La función devuelve el dataframe resultante.\n",
    "def obtener_importancias(df, model_name):\n",
    "    df['Model'] = model_name\n",
    "    if 'index' not in df.columns:\n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns={'index':'feature'})\n",
    "    df = df.sort_values(by='importance', ascending=False)\n",
    "    df = df.drop_duplicates(subset='feature', keep='first')\n",
    "    df = df[df['importance'] > 0]\n",
    "    important_features_list.append(df)\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbc vanilla\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este código evalúa un modelo de clasificación  utilizando el conjunto de datos dataset3. El código también muestra las características más importantes del modelo  utilizando la función show_important_features2. Esta función devuelve una lista con los nombres de las características más importantes del modelo.\n",
    "\n",
    "# El codigo se repite varias veces mas adelante haciendo el mismo procedimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model('gbc',dataset3)\n",
    "gbc = show_important_features2(\"gbc\")\n",
    "gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcstats = df1('gbc',0)\n",
    "gbcstats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ridgestats = eval_model2('ridge',dataset3)\n",
    "ridgestats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgestats = obtener_importancias(ridgestats, 'ridge')\n",
    "ridgestats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgestats2 = df1('ridge',1)\n",
    "Graficandoridgevanilla = ridgestats2\n",
    "ridgestats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ldastats = eval_model2('lda',dataset3)\n",
    "ldastats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastats = obtener_importancias(ldastats, 'lda')\n",
    "ldastats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastats2 = df1('lda',2)\n",
    "ldastats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "lrstats = eval_model2('lr',dataset3)\n",
    "lrstats  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrstats = obtener_importancias(lrstats, 'lr')\n",
    "lrstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrstats2 = df1('lr',3)\n",
    "Graficandolrvanilla = lrstats2\n",
    "lrstats2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "svmstats = eval_model2('svm',dataset3)\n",
    "svmstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmstats = obtener_importancias(svmstats, 'svm')\n",
    "svmstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmstats2 = df1('svm',4)\n",
    "svmstats2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost  vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model('catboost',dataset3)\n",
    "catboost = show_important_features2('catboost')\n",
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catbooststats = df1('catboost',5)\n",
    "Graficandocatboostvanilla = catbooststats\n",
    "catbooststats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model('xgboost',dataset3)\n",
    "xgboost = show_important_features2('xgboost')\n",
    "xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooststats =  df1('xgboost',6)\n",
    "xgbooststats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model('lightgbm',dataset3)\n",
    "lightgbm = show_important_features2('lightgbm')\n",
    "lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbmstats =  df1('lightgbm',7)\n",
    "lightgbmstats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model('rf',dataset3)\n",
    "rf = show_important_features2('rf')\n",
    "rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstats =  df1('rf',8)\n",
    "rfstats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### et vanilla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siguiente modelo\n",
    "eval_model('et',dataset3)\n",
    "et = show_important_features2('et')\n",
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etstats = df1('et',9)\n",
    "etstats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siguiente modelo\n",
    "eval_model('ada',dataset3)\n",
    "#evalua\n",
    "ada = show_important_features2('ada')\n",
    "ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adastats = df1('ada',10)\n",
    "adastats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siguiente modelo\n",
    "eval_model('dt',dataset3)\n",
    "#evalua\n",
    "dt = show_important_features2('dt')\n",
    "dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstats = df1('dt',11)\n",
    "dtstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "knnstats = eval_model2('knn',dataset3)\n",
    "knnstats\n",
    "knnstats2 = df1('knn',12)\n",
    "knnstats2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "qdastats = eval_model2('qda',dataset3)\n",
    "qdastats\n",
    "qdastats2 = df1('qda',13)\n",
    "qdastats2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "nbstats = eval_model2('nb',dataset3)\n",
    "nbstats\n",
    "nbstats2 = df1('nb',14)\n",
    "nbstats2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas vanilla Antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código llama a la función show_important_features() y luego imprime el resultado.\n",
    "# La función show_important_features() devuelve una lista de características importantes, \n",
    "# que luego se imprimen al usar la instrucción All.\n",
    "All = show_important_features()\n",
    "All\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código cuenta el número de veces que aparece cada valor en la columna 'Model' de una tabla o dataframe llamado All. Devuelve una serie con los valores únicos de la columna y el número de veces que aparecen.\n",
    "All['Model'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Entre modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Importancia entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función toma una lista de elementos y devuelve una lista con los elementos comunes entre ellos\n",
    "common_featuresVanilla = show_common_features(All)\n",
    "common_featuresVanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función calcula el total de importancia de todos los elementos en la lista All\n",
    "total_importanceVanilla = show_total_importance(All)\n",
    "total_importanceVanilla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función muestra una tabla de pivote con los datos de la variable All\n",
    "pivot_tableVanilla = show_pivot_table(All)\n",
    "pivot_tableVanilla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Esta línea llama a la función show_final_result() y le pasa como argumento el resultado de la tabla pivote generada con los datos de Vanilla.\n",
    "final_resultVanilla = show_final_result(pivot_tableVanilla)\n",
    "final_resultVanilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver las puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código está concatenando los resultados de diferentes modelos de\n",
    "# aprendizaje automático en un solo objeto llamado \"estadísticas\". \n",
    "# Esto se hace usando la función \"pd.concat\" de Pandas. Luego elimina la columna \n",
    "# \"Model\" del objeto y agrega una nueva columna \"Model\" con los nombres de los modelos \n",
    "# utilizados para generar los resultados. Finalmente establece el índice del objeto como la columna \n",
    "# \"Model\" y  guarda el objeto como \"resultadosVanilla\".\n",
    "stats = pd.concat([gbcstats,ridgestats2,ldastats2,lrstats2,svmstats2,catbooststats,xgbooststats,lightgbmstats,rfstats,etstats,adastats,dtstats,knnstats2,qdastats2,nbstats2],axis=0)\n",
    "stats = stats.drop('Model',axis=0)\n",
    "stats['Model'] = ['gbc',\"ridge\",\"lda\",\"lr\",\"svm\",'catboost','xgboost','lightgbm','rf','et','ada','dt',\"knnstats2\",\"qdastats2\",\"nbstats2\"]\n",
    "stats = stats.set_index('Model')\n",
    "stats['Model'] = ['gbc',\"ridge\",\"lda\",\"lr\",\"svm\",'catboost','xgboost','lightgbm','rf','et','ada','dt',\"knnstats2\",\"qdastats2\",\"nbstats2\"]\n",
    "resultadosVanilla=stats\n",
    "stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_importance(stats, title):\n",
    "    # cambiar tipo de letra a Times New Roman\n",
    "    font = {'family': 'Times New Roman',\n",
    "            'weight': 'bold',\n",
    "            'size': 20}\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    # elegir paleta de colores\n",
    "    colors = plt.cm.cividis(np.linspace(0, 1, 7))\n",
    "\n",
    "    # graficar las barras\n",
    "    stats.plot(kind='bar',figsize=(14,14), color=colors)\n",
    "\n",
    "    # establecer título del gráfico\n",
    "    plt.title(title, fontsize=30)\n",
    "\n",
    "    # establecer color del fondo\n",
    "    plt.rcParams['figure.facecolor'] = '#FFFFFF'\n",
    "\n",
    "    # ocultar rejilla\n",
    "    plt.grid(b=None)\n",
    "\n",
    "    # ajustar escala de Y\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "\n",
    "    # ajustar tamaño de letra y ubicación de la leyenda\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.87),fontsize=20)\n",
    "\n",
    "    # ajustar tamaño de letras del eje X y hacer que se muestren de lado\n",
    "    plt.tick_params(axis='x', labelsize=35,rotation=90)\n",
    "\n",
    "    # ajustar tamaño de letras del eje Y\n",
    "    plt.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    # establecer título del eje X\n",
    "    plt.xlabel('MODELO',fontsize = 35)\n",
    "\n",
    "    # establecer título del eje Y\n",
    "    plt.ylabel('IMPORTANCIA',fontsize = 35)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_importance(stats, title):\n",
    "    # cambiar tipo de letra a Times New Roman\n",
    "    font = {'family': 'Times New Roman',\n",
    "            'weight': 'bold',\n",
    "            'size': 20}\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    # elegir paleta de colores\n",
    "    colors = plt.cm.cividis(np.linspace(0, 1, 7))\n",
    "\n",
    "    # graficar las barras\n",
    "    stats.plot(kind='bar',figsize=(14,14), color=colors)\n",
    "\n",
    "    # establecer título del gráfico\n",
    "    plt.title(title, fontsize=30)\n",
    "\n",
    "    # establecer color del fondo\n",
    "    plt.rcParams['figure.facecolor'] = '#FFFFFF'\n",
    "\n",
    "    # ocultar rejilla\n",
    "    plt.grid(b=None)\n",
    "\n",
    "    # ajustar escala de Y\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "\n",
    "    # ajustar tamaño de letra y ubicación de la leyenda\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.87),fontsize=20)\n",
    "\n",
    "    # ajustar tamaño de letras del eje X y hacer que se muestren de lado\n",
    "    plt.tick_params(axis='x', labelsize=35,rotation=90)\n",
    "\n",
    "    # ajustar tamaño de letras del eje Y\n",
    "    plt.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    # establecer título del eje X\n",
    "    plt.xlabel('MODELO',fontsize = 35)\n",
    "\n",
    "    # establecer título del eje Y\n",
    "    plt.ylabel('IMPORTANCIA',fontsize = 35)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El código siguiente se utiliza para realizar un análisis de clasificación para el conjunto de datos \"dataset3\". El objetivo es predecir la variable \"tipo1\" y se establece un tamaño de entrenamiento del 75%. La división de datos se realiza con estratificación y se habilita la GPU. El proceso se realiza en silencio, con la selección de características habilitada y sin verbose. El ID de sesión es 123 y la normalización está habilitada. Por último, el código invoca el método compare_models() para comparar los modelos entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clf1 = setup(data = dataset3, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"classic\")\n",
    "compare_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "important_features_list = []\n",
    "result_list = []\n",
    "tuned_models_list = []\n",
    "predictions_list = []\n",
    "results_list = []\n",
    "\n",
    "def eval_modelClassic(model_name,datos):\n",
    "    # Inicializar el entorno de PyCaret\n",
    "    exp_clf1 = setup(data = datos, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"classic\")\n",
    "    set_config('seed', 123)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Hacer predicciones con el modelo\n",
    "    predictions = predict_model(best)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    tuned_models_list.append(tuned_model)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    result = pull()\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # Obtener la importancia de las características\n",
    "    columns = get_config('X_train').columns\n",
    "    importances = tuned_model.feature_importances_\n",
    "    important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "    important_features_list.append(important_features)\n",
    "    globals()[model_name] = tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "# Importar la función permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#feature_names list\n",
    "df_list = []\n",
    "important_features_list = []\n",
    "\n",
    "# Importar la función permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#feature_names list\n",
    "df_list = []\n",
    "\n",
    "def eval_model2Classic(model_name, df):\n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    resultado = pull()\n",
    "    result_list.append(resultado)\n",
    "    \n",
    "    if hasattr(tuned_model, 'feature_importances_'):\n",
    "        columns = df.columns\n",
    "        importances = tuned_model.feature_importances_\n",
    "        important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "        important_features_list.append(important_features)\n",
    "        globals()[model_name] = tuned_model\n",
    "        \n",
    "    elif hasattr(tuned_model, 'coef_'):\n",
    "        coef = tuned_model.coef_[0]\n",
    "        feature_names = list(df.columns)\n",
    "        feature_importances = dict(zip(feature_names, coef))\n",
    "        df2 = pd.DataFrame.from_dict(feature_importances, orient='index', columns=['importance'])        \n",
    "        df2 = df2.sort_values(by='importance', ascending=False)\n",
    "        df2['Model'] = model_name\n",
    "        df_list.append(df2)\n",
    "    if df_list:\n",
    "        result = pd.concat(df_list)\n",
    "        result = result[result['importance'] != 0]\n",
    "        #important_features_list.append(result)\n",
    "    else:\n",
    "        result = pd.DataFrame()\n",
    "    return result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('dt', dataset3)\n",
    "dt = show_important_features2('dt')\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstatsClassic = df1('dt',0)\n",
    "dtstatsClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ridgestats = eval_model2Classic('ridge',dataset3)\n",
    "ridgestats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgestats = obtener_importancias(ridgestats, 'ridge')\n",
    "ridgestats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgestatsClassic = df1('ridge',1)\n",
    "GraficandoridgeClassic = ridgestatsClassic\n",
    "ridgestatsClassic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "svmstats = eval_model2Classic('svm',dataset3)\n",
    "svmstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmstats = obtener_importancias(svmstats, 'svm')\n",
    "svmstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmstatsClassic = df1('svm',2)\n",
    "svmstatsClassic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "lrstats = eval_model2Classic('lr',dataset3)\n",
    "lrstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrstats = obtener_importancias(lrstats, 'lr')\n",
    "lrstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrstatsClassic = df1('lr',3)\n",
    "GraficandolrClassic = lrstatsClassic\n",
    "lrstatsClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ldastats = eval_model2Classic('lda',dataset3)\n",
    "ldastats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastats = obtener_importancias(ldastats, 'lda')\n",
    "ldastats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastatsClassic = df1('lda',4)\n",
    "ldastatsClassic\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('ada', dataset3)\n",
    "ada = show_important_features2('ada')\n",
    "ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adastatsClassic = df1('ada',5)\n",
    "adastatsClassic\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### et classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('et', dataset3)\n",
    "et = show_important_features2('et')\n",
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etstatsClassic = df1('et',6)\n",
    "etstatsClassic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('xgboost', dataset3)\n",
    "xgboost = show_important_features2('xgboost')\n",
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooststatsClassic = df1('xgboost',7)\n",
    "xgbooststatsClassic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbc classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('gbc', dataset3)\n",
    "gbc = show_important_features2('gbc')\n",
    "gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcstatsClassic = df1('gbc',8)\n",
    "gbcstatsClassic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('rf', dataset3)\n",
    "rf = show_important_features2('rf')\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstatsClassic = df1('rf',9)\n",
    "rfstatsClassic\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm classic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('lightgbm', dataset3)\n",
    "lightgbm = show_important_features2('lightgbm')\n",
    "lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbmstatsClassic = df1('lightgbm',10)\n",
    "lightgbmstatsClassic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassic('catboost', dataset3)\n",
    "catboost = show_important_features2('catboost')\n",
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catbooststatsClassic = df1('catboost',11)\n",
    "GraficandocatboostClassic = catbooststatsClassic\n",
    "catbooststatsClassic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "knnstatsClassic = eval_model2('knn',dataset3)\n",
    "knnstatsClassic\n",
    "knnstats2Classic = df1('knn',12)\n",
    "knnstats2Classic\n",
    "\n",
    "df_list = []\n",
    "qdastatsClassic = eval_model2('qda',dataset3)\n",
    "qdastatsClassic\n",
    "qdastats2Classic = df1('qda',13)\n",
    "qdastats2Classic\n",
    "\n",
    "df_list = []\n",
    "nbstatsClassic = eval_model2('nb',dataset3)\n",
    "nbstatsClassic\n",
    "nbstats2Classic = df1('nb',14)\n",
    "nbstats2Classic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas Classic Antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClasic = show_important_features()\n",
    "AllClasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClasic['Model'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entre Modelos Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_featuresClasic = show_common_features(AllClasic)\n",
    "common_featuresClasic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_importanceClasic = show_total_importance(AllClasic)\n",
    "total_importanceClasic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_tableClasic = show_pivot_table(AllClasic)\n",
    "pivot_tableClasic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultClasic = show_final_result(pivot_tableClasic)\n",
    "final_resultClasic\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando Puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosClasicos = pd.concat([dtstatsClassic,ridgestatsClassic,svmstatsClassic,lrstatsClassic,ldastatsClassic,adastatsClassic,etstatsClassic,xgbooststatsClassic,gbcstatsClassic,rfstatsClassic,lightgbmstatsClassic,catbooststatsClassic,knnstats2Classic,qdastats2Classic,nbstats2Classic], axis=0)\n",
    "resultadosClasicos = resultadosClasicos.drop('Model',axis=0)\n",
    "resultadosClasicos\n",
    "resultadosClasicos['Model'] = ['dt', 'ridge', 'svm', 'lr', 'lda', 'ada', 'et', 'xgboost', 'gbc', 'rf', 'lightgbm', 'catboost',\"knnstats2Classic\",\"qdastats2Classic\",\"nbstats2Classic\"]\n",
    "resultadosClasicos = resultadosClasicos.set_index('Model')\n",
    "resultadosClasicos\n",
    "resultadosClasicos['Model'] = ['dt', 'ridge', 'svm', 'lr', 'lda', 'ada', 'et', 'xgboost', 'gbc', 'rf', 'lightgbm', 'catboost',\"knnstats2Classic\",\"qdastats2Classic\",\"nbstats2Classic\"]\n",
    "resultadosClasicos "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clf1 = setup(data = dataset3, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"boruta\")\n",
    "compare_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo Boruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "important_features_list = []\n",
    "result_list = []\n",
    "tuned_models_list = []\n",
    "predictions_list = []\n",
    "results_list = []\n",
    "def eval_modelboruta(model_name,datos):\n",
    "    # Inicializar el entorno de PyCaret\n",
    "    exp_clf1 = setup(data = datos, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"boruta\")\n",
    "    set_config('seed', 123)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Hacer predicciones con el modelo\n",
    "    predictions = predict_model(best)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    tuned_models_list.append(tuned_model)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    result = pull()\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # Obtener la importancia de las características\n",
    "    columns = get_config('X_train').columns\n",
    "    importances = tuned_model.feature_importances_\n",
    "    important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "    important_features_list.append(important_features)\n",
    "    globals()[model_name] = tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "# Importar la función permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#feature_names list\n",
    "df_list = []\n",
    "important_features_list = []\n",
    "\n",
    "# Importar la función permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#feature_names list\n",
    "df_list = []\n",
    "\n",
    "def eval_model2boruta(model_name, df):\n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    resultado = pull()\n",
    "    result_list.append(resultado)\n",
    "    \n",
    "    if hasattr(tuned_model, 'feature_importances_'):\n",
    "        columns = df.columns\n",
    "        importances = tuned_model.feature_importances_\n",
    "        important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "        important_features_list.append(important_features)\n",
    "        globals()[model_name] = tuned_model\n",
    "        \n",
    "    elif hasattr(tuned_model, 'coef_'):\n",
    "        coef = tuned_model.coef_[0]\n",
    "        feature_names = list(df.columns)\n",
    "        feature_importances = dict(zip(feature_names, coef))\n",
    "        df2 = pd.DataFrame.from_dict(feature_importances, orient='index', columns=['importance'])        \n",
    "        df2 = df2.sort_values(by='importance', ascending=False)\n",
    "        df2['Model'] = model_name\n",
    "        df_list.append(df2)\n",
    "    if df_list:\n",
    "        result = pd.concat(df_list)\n",
    "        result = result[result['importance'] != 0]\n",
    "        #agregalos a la lista\n",
    "        #important_features_list.append(result)\n",
    "    else:\n",
    "        result = pd.DataFrame()\n",
    "    return result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('dt', dataset3)\n",
    "dt = show_important_features2('dt')\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstatsboruta = df1('dt',0)\n",
    "dtstatsboruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "svmstats = eval_model2boruta('svm',dataset3)\n",
    "svmstats\n",
    "svmstats = obtener_importancias(svmstats, 'svm')\n",
    "svmstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm f1 metodo\n",
    "svmstatsboruta = df1('svm',1)\n",
    "svmstatsboruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "lrstats = eval_model2boruta('lr',dataset3)\n",
    "lrstats\n",
    "lrstats = obtener_importancias(lrstats, 'lr')\n",
    "lrstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrstatsboruta = df1('lr',2)\n",
    "GraficandolrBoruta = lrstatsboruta\n",
    "lrstatsboruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ldastats = eval_model2boruta('lda',dataset3)\n",
    "ldastats\n",
    "ldastats = obtener_importancias(ldastats, 'lda')\n",
    "ldastats\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastatsboruta = df1('lda',3)\n",
    "ldastatsboruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ridgestats = eval_model2boruta('ridge',dataset3)\n",
    "ridgestats\n",
    "ridgestats = obtener_importancias(ridgestats, 'ridge')\n",
    "ridgestats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgestatsboruta = df1('ridge',4)\n",
    "GraficandoridgeBoruta = ridgestatsboruta\n",
    "ridgestatsboruta\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('ada', dataset3)\n",
    "ada = show_important_features2('ada')\n",
    "ada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adastatsboruta = df1('ada',5)\n",
    "adastatsboruta\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### et boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('et', dataset3)\n",
    "et = show_important_features2('et')\n",
    "et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etstatsboruta = df1('et',6)\n",
    "etstatsboruta\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('xgboost', dataset3)\n",
    "xgboost = show_important_features2('xgboost')\n",
    "xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooststatsboruta = df1('xgboost',7)\n",
    "xgbooststatsboruta\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbc boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('gbc', dataset3)\n",
    "gbc = show_important_features2('gbc')\n",
    "gbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcstatsboruta = df1('gbc',8)\n",
    "gbcstatsboruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf  boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('rf', dataset3)\n",
    "rf = show_important_features2('rf')\n",
    "rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstatsboruta = df1('rf',9)\n",
    "rfstatsboruta\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('lightgbm', dataset3)\n",
    "lightgbm = show_important_features2('lightgbm')\n",
    "lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbmstatsboruta = df1('lightgbm',10)\n",
    "lightgbmstatsboruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelboruta('catboost', dataset3)\n",
    "catboost = show_important_features2('catboost')\n",
    "catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catbooststatsboruta = df1('catboost',11)\n",
    "GraficandocatboostBoruta = catbooststatsboruta\n",
    "catbooststatsboruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "knnstatsboruta = eval_model2('knn',dataset3)\n",
    "knnstatsboruta\n",
    "knnstats2boruta = df1('knn',12)\n",
    "knnstats2boruta\n",
    "\n",
    "df_list = []\n",
    "qdastatsboruta = eval_model2('qda',dataset3)\n",
    "qdastatsboruta\n",
    "qdastats2boruta = df1('qda',13)\n",
    "qdastats2boruta\n",
    "\n",
    "df_list = []\n",
    "nbstatsboruta = eval_model2('nb',dataset3)\n",
    "nbstatsboruta\n",
    "nbstats2boruta = df1('nb',14)\n",
    "nbstats2boruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas Boruta Antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllBoruta = show_important_features()\n",
    "AllBoruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AllBoruta['Model'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entre modelos Boruta Antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_featuresBoruta = show_common_features(AllBoruta)\n",
    "common_featuresBoruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_importanceBoruta = show_total_importance(AllBoruta)\n",
    "total_importanceBoruta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tableBoruta = show_pivot_table(AllBoruta)\n",
    "pivot_tableBoruta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultBoruta = show_final_result(pivot_tableBoruta)\n",
    "final_resultBoruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver Puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosBoruta = pd.concat([dtstatsboruta, svmstatsboruta, lrstatsboruta, ldastatsboruta, ridgestatsboruta, adastatsboruta, etstatsboruta, xgbooststatsboruta, gbcstatsboruta, rfstatsboruta, lightgbmstatsboruta, catbooststatsboruta,knnstats2boruta,qdastats2boruta,nbstats2boruta], axis=0)\n",
    "resultadosBoruta\n",
    "resultadosBoruta = resultadosBoruta.drop('Model',axis=0)\n",
    "resultadosBoruta['Model'] =[\"dtstatsboruta\", \"svmstatsboruta\", \"lrstatsboruta\", \"ldastatsboruta\", \"ridgestatsboruta\", \"adastatsboruta\", \"etstatsboruta\", \"xgbooststatsboruta\",\" gbcstatsboruta\",\" rfstatsboruta\",\" lightgbmstatsboruta\",\" catbooststatsboruta\",\"knnstats2boruta\",\"qdastats2boruta\",\"nbstats2boruta\"]\n",
    "resultadosBoruta = resultadosBoruta.set_index('Model')\n",
    "resultadosBoruta['Model'] =[\"dtstatsboruta\", \"svmstatsboruta\", \"lrstatsboruta\", \"ldastatsboruta\", \"ridgestatsboruta\", \"adastatsboruta\", \"etstatsboruta\", \"xgbooststatsboruta\",\" gbcstatsboruta\",\" rfstatsboruta\",\" lightgbmstatsboruta\",\" catbooststatsboruta\",\"knnstats2boruta\",\"qdastats2boruta\",\"nbstats2boruta\"]\n",
    "resultadosBoruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos Boruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregando valores IC50 Y EC50 para balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3\n",
    "\n",
    "dataset3['type'] = dataset3['type1'].apply(lambda x: 'IC50' if x == 1 else 'EC50')\n",
    "dataset3.drop(['type1'], axis=1, inplace=True)\n",
    "dataset3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BALANCEO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este código realiza una técnica de muestreo llamada SMOTE (Synthetic Minority Over-sampling Technique) para manejar el desequilibrio de clases en los datos. Esta técnica genera nuevos ejemplos sintéticos para la clase minoritaria a partir de los ejemplos existentes. El código toma los datos X y y, así como el parámetro ignore, que especifica qué atributos ignorar durante el muestreo. Luego, se aplica SMOTE para generar nuevos ejemplos sintéticos. Los resultados se devuelven como X_resampled y y_resampled. Después de eso, se crea un DataFrame con los resultados del muestreo y se agrega la columna 'type'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel = dataset3\n",
    "resamplepadel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(resamplepadel.drop(['type'], axis=1), resamplepadel['type'])\n",
    "resamplepadel = pd.concat([X_res, y_res], axis=1)\n",
    "resamplepadel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_hue('type',resamplepadel.groupby(['type']).size().reset_index(name='count'),'type',['palevioletred', 'lightskyblue'],'Barplot','type','Count')\n",
    "resamplepadel.groupby(['type']).size().reset_index(name='count')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel.dtypes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel resamplepadel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel.to_excel('resamplepadel.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplepadel = pd.read_excel('resamplepadel.xlsx')\n",
    "resamplepadel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importantesDespues = resamplepadel\n",
    "importantesDespues['type1'] = importantesDespues['type'].apply(lambda x: 1 if x == 'IC50' else 2)\n",
    "#drop type\n",
    "importantesDespues.drop(['type'], axis=1, inplace=True)\n",
    "importantesDespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Despues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models Despues de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "s = setup(importantesDespues, target = 'type1', train_size=0.75, data_split_stratify=True,use_gpu=True, silent=True)\n",
    "compare_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "important_features_list = []\n",
    "result_list = []\n",
    "tuned_models_list = []\n",
    "predictions_list = []\n",
    "results_list = []\n",
    "\n",
    "def eval_modeld(model_name,datos):   \n",
    "    # Inicializar el entorno de PyCaret\n",
    "    exp_clf1 = setup(data = datos, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True)\n",
    "    set_config('seed', 123)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Hacer predicciones con el modelo\n",
    "    predictions = predict_model(best)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    tuned_models_list.append(tuned_model)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    result = pull()\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # Obtener la importancia de las características\n",
    "    columns = get_config('X_train').columns\n",
    "    importances = tuned_model.feature_importances_\n",
    "    important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "    important_features_list.append(important_features)\n",
    "    globals()[model_name] = tuned_model\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('dt', importantesDespues)\n",
    "dt = show_important_features2('dt')\n",
    "dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtstatsvanilladespues = df1('dt',0)\n",
    "dtstatsvanilladespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ridgestats = eval_model2('ridge',importantesDespues)\n",
    "ridgestats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridgestats = obtener_importancias(ridgestats, 'ridge')\n",
    "ridgestats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridgestatsvanilladespues = df1('ridge',1)\n",
    "GraficandoridgeVanilladespues = ridgestatsvanilladespues\n",
    "ridgestatsvanilladespues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list = []\n",
    "ldastats = eval_model2('lda',importantesDespues)\n",
    "ldastats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ldastats = obtener_importancias(ldastats, 'lda')\n",
    "ldastats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastatsvanilladespues = df1('lda',2)\n",
    "ldastatsvanilladespues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_list = []\n",
    "lrstats = eval_model2('lr',importantesDespues)\n",
    "lrstats  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "lrstats = obtener_importancias(lrstats, 'lr')\n",
    "lrstats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lrstatsvanilladespues = df1('lr',3)\n",
    "GraficandolrVanilladespues = lrstatsvanilladespues\n",
    "lrstatsvanilladespues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list = []\n",
    "svmstats = eval_model2('svm',importantesDespues)\n",
    "svmstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "svmstats = obtener_importancias(svmstats, 'svm')\n",
    "svmstats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "svmstatsvanilladespues = df1('svm',4)\n",
    "svmstatsvanilladespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('ada', importantesDespues)\n",
    "ada = show_important_features2('ada')\n",
    "ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adastatsVanilla  = df1('ada',5)\n",
    "adastatsVanilla \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### et vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('et', importantesDespues)\n",
    "et = show_important_features2('et')\n",
    "et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etstatsVanilla  = df1('et',6)\n",
    "etstatsVanilla \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('xgboost', importantesDespues)\n",
    "xgboost = show_important_features2('xgboost')\n",
    "xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooststatsVanilla  = df1('xgboost',7)\n",
    "xgbooststatsVanilla \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbc vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('gbc', importantesDespues)\n",
    "gbc = show_important_features2('gbc')\n",
    "gbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcstatsVanilla  = df1('gbc',8)\n",
    "gbcstatsVanilla \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('rf', importantesDespues)\n",
    "rf = show_important_features2('rf')\n",
    "rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstatsVanilla  = df1('rf',9)\n",
    "rfstatsVanilla \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('lightgbm', importantesDespues)\n",
    "lightgbm = show_important_features2('lightgbm')\n",
    "lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbmstatsVanilla  = df1('lightgbm',10)\n",
    "lightgbmstatsVanilla \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modeld('catboost', importantesDespues)\n",
    "catboost = show_important_features2('catboost')\n",
    "catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catbooststatsVanilla  = df1('catboost',11)\n",
    "GraficandocatboostVanilladespues = catbooststatsVanilla\n",
    "catbooststatsVanilla \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "knnstatsVanilla = eval_model2('knn',importantesDespues)\n",
    "knnstatsVanilla\n",
    "knnstats2Vanilla = df1('knn',12)\n",
    "knnstats2Vanilla\n",
    "\n",
    "df_list = []\n",
    "qdastatsVanilla = eval_model2('qda',importantesDespues)\n",
    "qdastatsVanilla\n",
    "qdastats2Vanilla = df1('qda',13)\n",
    "qdastats2Vanilla\n",
    "\n",
    "df_list = []\n",
    "nbstatsVanilla = eval_model2('nb',importantesDespues)\n",
    "nbstatsVanilla\n",
    "nbstats2Vanilla = df1('nb',14)\n",
    "nbstats2Vanilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todas Vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllVanillaDespues = show_important_features()\n",
    "AllVanillaDespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllVanillaDespues['Model'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre modelos Vanilla Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_featuresDespuesVanilla = show_common_features(AllVanillaDespues)\n",
    "common_featuresDespuesVanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_importanceDespuesVanilla = show_total_importance(AllVanillaDespues)\n",
    "total_importanceDespuesVanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tableDespuesVanilla= show_pivot_table(AllVanillaDespues)\n",
    "pivot_tableDespuesVanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultDespuesVanilla = show_final_result(pivot_tableDespuesVanilla)\n",
    "final_resultDespuesVanilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosVanillaDespues = pd.concat([dtstatsvanilladespues ,ridgestatsvanilladespues, ldastatsvanilladespues, lrstatsvanilladespues, svmstatsvanilladespues, adastatsVanilla, etstatsVanilla, xgbooststatsVanilla, gbcstatsVanilla, rfstatsVanilla, lightgbmstatsVanilla, catbooststatsVanilla,nbstats2Vanilla, qdastats2Vanilla ,knnstats2Vanilla], axis=0)\n",
    "resultadosVanillaDespues\n",
    "resultadosVanillaDespues = resultadosVanillaDespues.drop('Model',axis=0)\n",
    "resultadosVanillaDespues['Model'] =[\"dtstatsvanilladespues \",\"ridgestatsvanilladespues\", \"ldastatsvanilladespues\", \"lrstatsvanilladespues\", \"svmstatsvanilladespues\", \"adastatsVanilla\", \"etstatsVanilla\", \"xgbooststatsVanilla\", \"gbcstatsVanilla\", \"rfstatsVanilla\", \"lightgbmstatsVanilla\", \"catbooststatsVanilla\",\"nbstats2Vanilla \",\"qdastats2Vanilla\", \"knnstats2Vanilla\"]\n",
    "resultadosVanillaDespues = resultadosVanillaDespues.set_index('Model')\n",
    "resultadosVanillaDespues['Model'] =[\"dtstatsvanilladespues \",\"ridgestatsvanilladespues\", \"ldastatsvanilladespues\", \"lrstatsvanilladespues\", \"svmstatsvanilladespues\", \"adastatsVanilla\", \"etstatsVanilla\", \"xgbooststatsVanilla\", \"gbcstatsVanilla\", \"rfstatsVanilla\", \"lightgbmstatsVanilla\", \"catbooststatsVanilla\",\"nbstats2Vanilla \",\"qdastats2Vanilla\", \"knnstats2Vanilla\"]\n",
    "resultadosVanillaDespues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic balanceado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clf1 = setup(data = importantesDespues, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"classic\")\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "important_features_list = []\n",
    "tuned_models_list = []\n",
    "predictions_list = []\n",
    "results_list = []\n",
    "result_list = []\n",
    "def eval_modelClassicd(model_name,datos):\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Inicializar el entorno de PyCaret\n",
    "    exp_clf1 = setup(data = datos, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"classic\")\n",
    "    set_config('seed', 123)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Hacer predicciones con el modelo\n",
    "    predictions = predict_model(best)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    tuned_models_list.append(tuned_model)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    result = pull()\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # Obtener la importancia de las características\n",
    "    columns = get_config('X_train').columns\n",
    "    importances = tuned_model.feature_importances_\n",
    "    important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "    important_features_list.append(important_features)\n",
    "    globals()[model_name] = tuned_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('dt', importantesDespues)\n",
    "dt = show_important_features2('dt')\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstatsClassicdespues  = df1('dt',0)\n",
    "dtstatsClassicdespues \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ridgestats =eval_model2Classic('ridge',importantesDespues)\n",
    "ridgestats\n",
    "\n",
    "ridgestats = obtener_importancias(ridgestats, 'ridge')\n",
    "ridgestats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridgestatsClassicdespues  = df1('ridge',1)\n",
    "GraficandoridgeClassicdespues = ridgestatsClassicdespues\n",
    "ridgestatsClassicdespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_list = []\n",
    "ldastats = eval_model2Classic('lda',importantesDespues)\n",
    "ldastats\n",
    "\n",
    "ldastats = obtener_importancias(ldastats, 'lda')\n",
    "ldastats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ldastatsClassicdespues  = df1('lda',2)\n",
    "ldastatsClassicdespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_list = []\n",
    "lrstats = eval_model2Classic('lr',importantesDespues)\n",
    "lrstats  \n",
    "\n",
    "\n",
    "lrstats = obtener_importancias(lrstats, 'lr')\n",
    "lrstats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "lrstatsClassicdespues  = df1('lr',3)\n",
    "GraficandolrClassicdespues = lrstatsClassicdespues\n",
    "lrstatsClassicdespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "svmstats =eval_model2Classic('svm',importantesDespues)\n",
    "svmstats\n",
    "\n",
    "svmstats = obtener_importancias(svmstats, 'svm')\n",
    "svmstats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmstatsClassicdespues  = df1('svm',4)\n",
    "svmstatsClassicdespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('ada', importantesDespues)\n",
    "ada = show_important_features2('ada')\n",
    "ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adastatsClassicdespues  = df1('ada',5)\n",
    "adastatsClassicdespues \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### et Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('et', importantesDespues)\n",
    "et = show_important_features2('et')\n",
    "et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etstatsClassicdespues  = df1('et',6)\n",
    "etstatsClassicdespues \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('xgboost', importantesDespues)\n",
    "xgboost = show_important_features2('xgboost')\n",
    "xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooststatsClassicdespues  = df1('xgboost',7)\n",
    "xgbooststatsClassicdespues \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbc Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('gbc', importantesDespues)\n",
    "gbc = show_important_features2('gbc')\n",
    "gbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcstatsClassicdespues  = df1('gbc',8)\n",
    "gbcstatsClassicdespues \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('rf', importantesDespues)\n",
    "rf = show_important_features2('rf')\n",
    "rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstatsClassicdespues  = df1('rf',9)\n",
    "rfstatsClassicdespues \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('lightgbm', importantesDespues)\n",
    "lightgbm = show_important_features2('lightgbm')\n",
    "lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbmstatsClassicdespues  = df1('lightgbm',10)\n",
    "lightgbmstatsClassicdespues \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost Classic Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelClassicd('catboost', importantesDespues)\n",
    "catboost = show_important_features2('catboost')\n",
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catbooststatsClassicdespues  = df1('catboost',11)\n",
    "GraficandocatboostClassicdespues = catbooststatsClassicdespues\n",
    "catbooststatsClassicdespues \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "knnstatsClassicdespues = eval_model2('knn',importantesDespues)\n",
    "knnstatsClassicdespues\n",
    "knnstats2Classicdespues = df1('knn',12)\n",
    "knnstats2Classicdespues\n",
    "\n",
    "df_list = []\n",
    "qdastatsClassicdespues = eval_model2('qda',importantesDespues)\n",
    "qdastatsClassicdespues\n",
    "qdastats2Classicdespues = df1('qda',13)\n",
    "qdastats2Classicdespues\n",
    "\n",
    "df_list = []\n",
    "nbstatsClassicdespues = eval_model2('nb',importantesDespues)\n",
    "nbstatsClassicdespues\n",
    "nbstats2Classicdespues = df1('nb',14)\n",
    "nbstats2Classicdespues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todas Classic Despues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClassicDespues = show_important_features()\n",
    "AllClassicDespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClassicDespues['Model'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Modelos Classic Despues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_featuresDespuesClassic = show_common_features(AllClassicDespues)\n",
    "common_featuresDespuesClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_importanceDespuesClassic = show_total_importance(AllClassicDespues)\n",
    "total_importanceDespuesClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tableDespuesClassic = show_pivot_table(AllClassicDespues)\n",
    "pivot_tableDespuesClassic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultDespues = show_final_result(pivot_tableDespuesClassic)\n",
    "final_resultDespues\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosClassicDespues = pd.concat([dtstatsClassicdespues ,ridgestatsClassicdespues ,ldastatsClassicdespues ,lrstatsClassicdespues ,svmstatsClassicdespues ,adastatsClassicdespues ,etstatsClassicdespues ,xgbooststatsClassicdespues ,gbcstatsClassicdespues ,rfstatsClassicdespues ,lightgbmstatsClassicdespues ,catbooststatsClassicdespues,knnstats2Classicdespues,qdastats2Classicdespues,nbstats2Classicdespues ], axis=0)\n",
    "resultadosClassicDespues\n",
    "resultadosClassicDespues = resultadosClassicDespues.drop('Model',axis=0)\n",
    "resultadosClassicDespues['Model'] =[\"dtstatsClassicdespues \",\"ridgestatsClassicdespues\", \"ldastatsClassicdespues\", \"lrstatsClassicdespues\", \"svmstatsClassicdespues\", \"adastatsClassicdespues\", \"etstatsClassicdespues\", \"xgbooststatsClassicdespues\", \"gbcstatsClassicdespues\", \"rfstatsClassicdespues\", \"lightgbmstatsClassicdespues\", \"catbooststatsClassicdespues\",\"knnstats2Classicdespues\",\"qdastats2Classicdespues\",\"nbstats2Classicdespues\" ]\n",
    "resultadosClassicDespues = resultadosClassicDespues.set_index('Model')\n",
    "resultadosClassicDespues['Model'] =[\"dtstatsClassicdespues \",\"ridgestatsClassicdespues\", \"ldastatsClassicdespues\", \"lrstatsClassicdespues\", \"svmstatsClassicdespues\", \"adastatsClassicdespues\", \"etstatsClassicdespues\", \"xgbooststatsClassicdespues\", \"gbcstatsClassicdespues\", \"rfstatsClassicdespues\", \"lightgbmstatsClassicdespues\", \"catbooststatsClassicdespues\",\"knnstats2Classicdespues\",\"qdastats2Classicdespues\",\"nbstats2Classicdespues\" ]\n",
    "resultadosClassicDespues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clf1 = setup(data = importantesDespues, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"boruta\")\n",
    "compare_models(sort='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "important_features_list = []\n",
    "important_features_list = []\n",
    "tuned_models_list = []\n",
    "predictions_list = []\n",
    "results_list = []\n",
    "result_list = []\n",
    "def eval_modelborutad(model_name,datos):\n",
    "\n",
    "    \n",
    "    # Inicializar el entorno de PyCaret\n",
    "    exp_clf1 = setup(data = datos, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"boruta\")\n",
    "    set_config('seed', 123)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    best = create_model(model_name)\n",
    "    \n",
    "    # Hacer predicciones con el modelo\n",
    "    predictions = predict_model(best)\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "    # Sintonizar el modelo\n",
    "    tuned_model = tune_model(best,optimize='Accuracy')\n",
    "    tuned_models_list.append(tuned_model)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo\n",
    "    results = evaluate_model(tuned_model)\n",
    "    results_list.append(results)\n",
    "    result = pull()\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # Obtener la importancia de las características\n",
    "    columns = get_config('X_train').columns\n",
    "    importances = tuned_model.feature_importances_\n",
    "    important_features = pd.DataFrame({'feature': columns, 'importance': importances, 'Model' : model_name})\n",
    "    important_features_list.append(important_features)\n",
    "    globals()[model_name] = tuned_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt Boruta Despues  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('dt', importantesDespues)\n",
    "dt = show_important_features2('dt')\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstatsborutadespues  = df1('dt',0)\n",
    "dtstatsborutadespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ridgestats =eval_model2Classic('ridge',importantesDespues)\n",
    "ridgestats\n",
    "\n",
    "ridgestats = obtener_importancias(ridgestats, 'ridge')\n",
    "ridgestats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgestatsborutadespues  = df1('ridge',1)\n",
    "GraficandoridgeBorutadespues = ridgestatsborutadespues\n",
    "ridgestatsborutadespues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list = []\n",
    "ldastats = eval_model2boruta('lda',importantesDespues)\n",
    "ldastats\n",
    "\n",
    "ldastats = obtener_importancias(ldastats, 'lda')\n",
    "ldastats\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldastatsborutadespues  = df1('lda',2)\n",
    "ldastatsborutadespues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list = []\n",
    "lrstats = eval_model2boruta('lr',importantesDespues)\n",
    "lrstats  \n",
    "\n",
    "\n",
    "lrstats = obtener_importancias(lrstats, 'lr')\n",
    "lrstats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrstatsborutadespues  = df1('lr',3)\n",
    "GraficandolrBorutadespues = lrstatsborutadespues\n",
    "lrstatsborutadespues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "svmstats =eval_model2boruta('svm',importantesDespues)\n",
    "svmstats\n",
    "\n",
    "svmstats = obtener_importancias(svmstats, 'svm')\n",
    "svmstats\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmstatsborutadespues  = df1('svm',4)\n",
    "svmstatsborutadespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_modelborutad('ada', importantesDespues)\n",
    "ada = show_important_features2('ada')\n",
    "ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adastatsBorutaDespues = df1('ada',5)\n",
    "adastatsBorutaDespues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### et Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('et', importantesDespues)\n",
    "et = show_important_features2('et')\n",
    "et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etstatsBorutaDespues = df1('et',6)\n",
    "etstatsBorutaDespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('xgboost', importantesDespues)\n",
    "xgboost = show_important_features2('xgboost')\n",
    "xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooststatsBorutaDespues = df1('xgboost',7)\n",
    "xgbooststatsBorutaDespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gbc Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('gbc', importantesDespues)\n",
    "gbc = show_important_features2('gbc')\n",
    "gbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcstatsBorutaDespues = df1('gbc',8)\n",
    "gbcstatsBorutaDespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('rf', importantesDespues)\n",
    "rf = show_important_features2('rf')\n",
    "rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstatsBorutaDespues = df1('rf',9)\n",
    "rfstatsBorutaDespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lighgbm Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('lightgbm', importantesDespues)\n",
    "lightgbm = show_important_features2('lightgbm')\n",
    "lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbmstatsBorutaDespues = df1('lightgbm',10)\n",
    "lightgbmstatsBorutaDespues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost Boruta Despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_modelborutad('catboost', importantesDespues)\n",
    "catboost = show_important_features2('catboost')\n",
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grafica roc curve de catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catbooststatsBorutaDespues = df1('catboost',11)\n",
    "GraficandocatboostBorutadespues = catbooststatsBorutaDespues\n",
    "catbooststatsBorutaDespues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "knnstatsBorutaDespues = eval_model2('knn',importantesDespues)\n",
    "knnstatsBorutaDespues\n",
    "knnstats2BorutaDespues = df1('knn',12)\n",
    "knnstats2BorutaDespues\n",
    "\n",
    "df_list = []\n",
    "qdastatsBorutaDespues = eval_model2('qda',importantesDespues)\n",
    "qdastatsBorutaDespues\n",
    "qdastats2BorutaDespues = df1('qda',13)\n",
    "qdastats2BorutaDespues\n",
    "\n",
    "df_list = []\n",
    "nbstatsBorutaDespues = eval_model2('nb',importantesDespues)\n",
    "nbstatsBorutaDespues\n",
    "nbstats2BorutaDespues = df1('nb',14)\n",
    "nbstats2BorutaDespues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todas Boruta Despues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllBorutaDespues = show_important_features()\n",
    "AllBorutaDespues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllBorutaDespues['Model'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre modelos Boruta Despues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_featuresDespuesBoruta = show_common_features(AllBorutaDespues)\n",
    "common_featuresDespuesBoruta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_importanceDespuesBoruta = show_total_importance(AllBorutaDespues)\n",
    "total_importanceDespuesBoruta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_tableDespuesBoruta = show_pivot_table(AllBorutaDespues)\n",
    "pivot_tableDespuesBoruta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultDespuesBoruta = show_final_result(pivot_tableDespuesBoruta)\n",
    "final_resultDespuesBoruta\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver Puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código concatena varios conjuntos de datos (dtstatsborutadespues, ridgestatsborutadespues, ldastatsborutadespues, etc.) en un solo conjunto de datos llamado resultadosBorutaDespues. Luego elimina la columna 'Model' y la reemplaza con una lista de nombres de modelos. Por último, establece el índice del conjunto de datos como 'Model'.\n",
    "resultadosBorutaDespues = pd.concat([dtstatsborutadespues ,ridgestatsborutadespues ,ldastatsborutadespues ,lrstatsborutadespues ,svmstatsborutadespues ,adastatsBorutaDespues ,etstatsBorutaDespues ,xgbooststatsBorutaDespues ,gbcstatsBorutaDespues ,rfstatsBorutaDespues ,lightgbmstatsBorutaDespues ,catbooststatsBorutaDespues,knnstats2BorutaDespues,qdastats2BorutaDespues,nbstats2BorutaDespues ], axis=0)\n",
    "resultadosBorutaDespues\n",
    "resultadosBorutaDespues = resultadosBorutaDespues.drop('Model',axis=0)\n",
    "resultadosBorutaDespues['Model'] =[\"dtstatsborutadespues \",\"ridgestatsborutadespues\", \"ldastatsborutadespues\", \"lrstatsborutadespues\", \"svmstatsborutadespues\", \"adastatsBorutaDespues\", \"etstatsBorutaDespues\", \"xgbooststatsBorutaDespues\", \"gbcstatsBorutaDespues\", \"rfstatsBorutaDespues\", \"lightgbmstatsBorutaDespues\", \"catbooststatsBorutaDespues\",\"knnstats2BorutaDespues\",\"qdastats2BorutaDespues\",\"nbstats2BorutaDespues\"]\n",
    "resultadosBorutaDespues = resultadosBorutaDespues.set_index('Model')\n",
    "resultadosBorutaDespues['Model'] =[\"dtstatsborutadespues \",\"ridgestatsborutadespues\", \"ldastatsborutadespues\", \"lrstatsborutadespues\", \"svmstatsborutadespues\", \"adastatsBorutaDespues\", \"etstatsBorutaDespues\", \"xgbooststatsBorutaDespues\", \"gbcstatsBorutaDespues\", \"rfstatsBorutaDespues\", \"lightgbmstatsBorutaDespues\", \"catbooststatsBorutaDespues\",\"knnstats2BorutaDespues\",\"qdastats2BorutaDespues\",\"nbstats2BorutaDespues\"]\n",
    "resultadosBorutaDespues\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes_graficos_final_vanilla = pd.concat([Graficandoridgevanilla, Graficandolrvanilla, Graficandocatboostvanilla])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes_graficos_final_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes_graficos_final_Classic = pd.concat([GraficandoridgeClassic, GraficandolrClassic, GraficandocatboostClassic])\n",
    "Antes_graficos_final_Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes_graficos_final_Boruta = pd.concat([GraficandolrBoruta, GraficandoridgeBoruta, GraficandocatboostBoruta])\n",
    "Antes_graficos_final_Boruta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despues de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Despues_graficos_final_Vanilla = pd.concat([GraficandoridgeVanilladespues, GraficandolrVanilladespues, GraficandocatboostVanilladespues])\n",
    "Despues_graficos_final_Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Despues_graficos_final_Classic = pd.concat([GraficandoridgeClassicdespues, GraficandolrClassicdespues, GraficandocatboostClassicdespues])\n",
    "Despues_graficos_final_Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Despues_graficos_final_Boruta = pd.concat([GraficandoridgeBorutadespues, GraficandolrBorutadespues, GraficandocatboostBorutadespues])\n",
    "Despues_graficos_final_Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanilla.T\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.reset_index()\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={'index':'Model'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={0:'Accuracy'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={1:'AUC'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={2:'Recall'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={3:'Prec.'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={4:'F1'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={5:'Kappa'})\n",
    "Antes_graficos_final_vanillatest = Antes_graficos_final_vanillatest.rename(columns={6:'MCC'})\n",
    "Antes_graficos_final_vanillatest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados a Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosVanilla.to_excel('resultadosVanilla.xlsx')\n",
    "resultadosClasicos.to_excel('resultadosClasicos.xlsx')\n",
    "resultadosBoruta.to_excel('resultadosBoruta.xlsx')\n",
    "resultadosVanillaDespues.to_excel('resultadosVanillaDespues.xlsx')\n",
    "resultadosClassicDespues.to_excel('resultadosClassicDespues.xlsx')\n",
    "resultadosBorutaDespues.to_excel('resultadosBorutaDespues.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosVanilla = pd.read_excel('resultadosVanilla.xlsx')\n",
    "resultadosClasicos = pd.read_excel('resultadosClasicos.xlsx')\n",
    "resultadosBoruta = pd.read_excel('resultadosBoruta.xlsx')\n",
    "resultadosVanillaDespues = pd.read_excel('resultadosVanillaDespues.xlsx')\n",
    "resultadosClassicDespues = pd.read_excel('resultadosClassicDespues.xlsx')\n",
    "resultadosBorutaDespues = pd.read_excel('resultadosBorutaDespues.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código define una función llamada boxplot_compare que se utiliza para crear un gráfico de caja y bigotes. Esta función toma como parámetros un marco de datos, una variable numérica, etiquetas para el eje x y el eje y, así como un título. La función crea entonces un gráfico de caja y bigotes con los datos especificados, con los parámetros dados para el eje x, el eje y y el título. La función también establece límites en el eje y para asegurar que los resultados sean visibles.\n",
    "def boxplot_compare(df, var_num, labelx, labely, title):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5), dpi=160)\n",
    "    ax.boxplot(df[var_num].values, labels=var_num)\n",
    "    plt.xlabel(labelx, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(labely, fontsize=14, fontweight='bold')\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.setp(plt.gca().artists, edgecolor = 'k', facecolor='w')\n",
    "    plt.ylim(0.80, 0.95)\n",
    "    plt.setp(plt.gca().lines, color='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código crea un diagrama de caja (boxplot) a partir de un dataframe, una columna, un grupo por el que agrupar los datos, el tamaño de la figura y etiquetas para los ejes x e y. Además, se especifica un título para el gráfico. El código también establece la rotación del eje x en 90 grados y configura los bordes y los colores de los artistas y líneas del gráfico. Finalmente, muestra el gráfico.\n",
    "def create_boxplot_v2(dataframe, column, by, figsize, labelx, labely, title):\n",
    "    dataframe.boxplot(column=column, by=by, figsize=figsize)\n",
    "    plt.xlabel(labelx, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(labely, fontsize=14, fontweight='bold')\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.setp(plt.gca().artists, edgecolor = 'k', facecolor='w')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.setp(plt.gca().lines, color='k')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código importa la biblioteca matplotlib.pyplot como plt y luego define una \n",
    "# función llamada plot_boxplots_subplots. Esta función toma tres \n",
    "# argumentos: df_list, columns y labels. Estos argumentos se utilizan para crear una gráfica de caja con subplots. La gráfica de caja se genera usando los datos de los dataframes en df_list, las columnas especificadas en columns y los títulos especificados en labels. La función configura el tamaño de la figura, los límites del eje y, además, establece algunas opciones de \n",
    "# estilo para la gráfica como el color de los bordes, el color del fondo y el color de las líneas.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_boxplots_subplots(df_list, columns, labels):\n",
    "    rows=4\n",
    "    cols=3\n",
    "    n=1\n",
    "    for i, df in enumerate(df_list):\n",
    "        ax = plt.subplot(rows, cols, n)\n",
    "        ax.boxplot(df[columns].values)\n",
    "        plt.gcf().set_size_inches(15, 15)\n",
    "        plt.ylim(0.80, 0.90)\n",
    "        ax.set_title(labels[i])\n",
    "        plt.gcf().set_dpi(100)\n",
    "        plt.xticks(fontweight='bold')\n",
    "        plt.yticks(fontweight='bold')\n",
    "        plt.title(labels[i].upper(), fontweight='bold')\n",
    "        plt.gcf().set_dpi(100)\n",
    "        plt.setp(plt.gca().artists, edgecolor = 'k', facecolor='w')\n",
    "        plt.setp(plt.gca().lines, color='k')\n",
    "        plt.setp(plt.gca().spines.values(), color='k')\n",
    "        plt.setp(plt.gca().spines.values(), alpha=1)\n",
    "        plt.setp(plt.gca().spines.values(), color='k')\n",
    "\n",
    "        n+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código crea un gráfico de caja y bigote usando la biblioteca plotly.express. El parámetro \"dataframe\" es un marco de datos que contiene los datos a representar. El parámetro \"column\" es el nombre de la columna del marco de datos que contiene los valores a representar. El parámetro \"by\" es el nombre de la columna del marco de datos que contiene los grupos para los cuales se deben agrupar los valores. Los parámetros \"figsize\", \"labelx\", \"labely\" y \"title\" son usados para definir el tamaño, etiquetas y título del gráfico respectivamente. El código también actualiza el eje Y para limitar su rango entre 0,80 y 0,95. Finalmente, muestra el gráfico generado.\n",
    "import plotly.express as px\n",
    "\n",
    "def create_boxplot_test2(dataframe, column, by, figsize, labelx, labely, title):\n",
    "    fig = px.box(dataframe, x=by, y=column, title=title, labels={'x':labelx, 'y':labely}, color=by)\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(\n",
    "            range=[0.80, 0.95]\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código crea un gráfico de caja para comparar los resultados de varias pruebas. Utiliza la biblioteca Plotly Graph Objects para crear el gráfico. El código toma un dataframe, una lista de columnas y un parámetro \"by\" como entradas. Luego, crea un gráfico de caja para cada columna en la lista de columnas. El gráfico se actualiza dinámicamente con los botones para mostrar solo los resultados específicos que el usuario desea ver. El título del gráfico se actualiza dinámicamente dependiendo del resultado que se esté mostrando.\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def create_boxplot_test5(dataframe, columns, by):\n",
    "    def update_title(col):\n",
    "        if col == 'MCC':\n",
    "            return 'MCC Score Comparison'\n",
    "        elif col == 'F1':\n",
    "            return 'F1 Score Comparison'\n",
    "        elif col == 'Kappa':\n",
    "            return 'Kappa Score Comparison'\n",
    "        else:\n",
    "            return 'Score Comparison'\n",
    "    \n",
    "    colors = {'MCC':'blue','F1':'green','Kappa':'red'}\n",
    "    fig = go.Figure()\n",
    "    for column in columns:\n",
    "        fig.add_trace(go.Box(x=dataframe[by], y=dataframe[column], name=column, boxpoints='all',line=dict(color=colors.get(column,'black'))))\n",
    "    fig.update_layout(updatemenus=[\n",
    "        dict(\n",
    "            type='buttons',\n",
    "            showactive=False,\n",
    "            buttons=[dict(\n",
    "                label=col,\n",
    "                method='update',\n",
    "                args=[{'visible': [col == i for i in columns]},\n",
    "                      {'title': update_title(col)}]) for col in columns])])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosVanilla\n",
    "resultadosVanilla['Metodo'] = 'Vanilla'\n",
    "resultadosVanilla = resultadosVanilla.loc[:, ~resultadosVanilla.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosClasicos\n",
    "resultadosClasicos['Metodo'] = 'Classic'\n",
    "#quita todas las columnas que digan Unnamed\n",
    "resultadosClasicos = resultadosClasicos.loc[:, ~resultadosClasicos.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosBoruta\n",
    "#crea una columna llamada metodo y se le pone boruta\n",
    "resultadosBoruta['Metodo'] = 'Boruta'\n",
    "#quita todas las columnas que digan Unnamed\n",
    "resultadosBoruta = resultadosBoruta.loc[:, ~resultadosBoruta.columns.str.contains('^Unnamed')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este código se utiliza para combinar los resultados de varios modelos de aprendizaje automático. Primero, concatena los resultados de los modelos \"Vanilla\", \"Clásicos\" y \"Boruta\" en una sola tabla llamada resultadosAll. Luego, elimina la columna 'Model.1' de la tabla. A continuación, reemplaza todas las cadenas que contienen 'statsboruta', 'stats2Classic', 'stats2', 'stats2boruta' y 'boruta' con una cadena vacía en la columna 'Model'. Finalmente, elimina las columnas 'Accuracy', 'AUC', 'Recall' y 'Prec.' y luego limpia cualquier espacio en blanco en la columna 'Model'. Por último, imprime el resultado final.\n",
    "resultadosAll = pd.concat([resultadosVanilla, resultadosClasicos, resultadosBoruta])\n",
    "resultadosAll = resultadosAll.drop(['Model.1'], axis=1)\n",
    "resultadosAll['Model'] = resultadosAll['Model'].str.replace('statsboruta', '')\n",
    "resultadosAll['Model'] = resultadosAll['Model'].str.replace('stats2Classic', '')\n",
    "resultadosAll['Model'] = resultadosAll['Model'].str.replace('stats2', '')\n",
    "resultadosAll['Model'] = resultadosAll['Model'].str.replace('stats2boruta', '')\n",
    "resultadosAll['Model'] = resultadosAll['Model'].str.replace('boruta', '')\n",
    "resultadosAll = resultadosAll.drop(['Accuracy', 'AUC', 'Recall', 'Prec.'], axis=1)\n",
    "resultadosAll['Model'] = resultadosAll['Model'].str.strip()\n",
    "resultadosAll\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_test2(resultadosAll, 'F1', 'Metodo', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_test2(resultadosAll, 'F1', 'Model', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')\n",
    "create_boxplot_test2(resultadosAll, 'MCC', 'Model', (10, 10), 'Metodos', 'MCC Score', 'MCC Score Comparison')\n",
    "create_boxplot_test2(resultadosAll, 'Kappa', 'Model', (10, 10), 'Metodos', 'Kappa Score', 'Kappa Score Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_test5(resultadosAll, ['MCC', 'F1', 'Kappa'], 'Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_v2(resultadosAll, 'MCC', 'Metodo', (10, 10), 'Metodos', 'MCC Score', 'MCC Score Comparison')\n",
    "create_boxplot_v2(resultadosAll, 'F1', 'Metodo', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')\n",
    "create_boxplot_v2(resultadosAll, 'Kappa', 'Metodo', (10, 10), 'Metodos', 'Kappa Score', 'Kappa Score Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_v2(resultadosAll, 'MCC', 'Model', (10, 10), 'Models', 'MCC Score', 'MCC Score Comparison')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_boxplot_v2(resultadosAll, 'F1', 'Model', (10, 10), 'Models', 'F1 Score', 'F1 Score Comparison')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_boxplot_v2(resultadosAll, 'Kappa', 'Model', (10, 10), 'Models', 'Kappa Score', 'Kappa Score Comparison')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloslista = list(resultadosAll['Model'].unique())\n",
    "modeloslista\n",
    "resultadosAllList = []\n",
    "for i in modeloslista:\n",
    "    resultadosAllList.append(resultadosAll[resultadosAll['Model'] == i.strip()])\n",
    "resultadosAllList\n",
    "\n",
    "resultadosAllList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosVanillaDespues\n",
    "resultadosVanillaDespues = resultadosVanillaDespues.loc[:, ~resultadosVanillaDespues.columns.str.contains('^Unnamed')]\n",
    "resultadosVanillaDespues['Metodo'] = 'Vanilla'\n",
    "resultadosVanillaDespues['Model'] = resultadosVanillaDespues['Model'].str.replace('statsvanilladespues', '')\n",
    "resultadosVanillaDespues['Model'] = resultadosVanillaDespues['Model'].str.replace('statsVanilla', '')\n",
    "resultadosVanillaDespues['Model'] = resultadosVanillaDespues['Model'].str.replace('stats2Vanilla', '')\n",
    "resultadosVanillaDespues['Model'] = resultadosVanillaDespues['Model'].str.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosClassicDespues\n",
    "resultadosClassicDespues = resultadosClassicDespues.loc[:, ~resultadosClassicDespues.columns.str.contains('^Unnamed')]\n",
    "resultadosClassicDespues['Metodo'] = 'Classic'\n",
    "resultadosClassicDespues['Model'] = resultadosClassicDespues['Model'].str.replace('statsclassicdespues', '')\n",
    "resultadosClassicDespues['Model'] = resultadosClassicDespues['Model'].str.replace('statsClassic', '')\n",
    "resultadosClassicDespues['Model'] = resultadosClassicDespues['Model'].str.replace('despues', '')\n",
    "resultadosClassicDespues['Model'] = resultadosClassicDespues['Model'].str.replace('stats2Classic', '')\n",
    "resultadosClassicDespues['Model'] = resultadosClassicDespues['Model'].str.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosBorutaDespues\n",
    "resultadosBorutaDespues = resultadosBorutaDespues.loc[:, ~resultadosBorutaDespues.columns.str.contains('^Unnamed')]\n",
    "resultadosBorutaDespues['Metodo'] = 'Boruta'\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('statsborutadespues', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('statsBoruta', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('despues', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('Despues', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('boruta', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('stats2Vanilla', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('stats2Classi', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('stats2Boruta', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('stats2Vanilla', '')\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.replace('stats2Classic', '')\n",
    "#borra el espacio que tengan delante o detras cada modelo\n",
    "resultadosBorutaDespues['Model'] = resultadosBorutaDespues['Model'].str.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosAllDespues = pd.concat([resultadosVanillaDespues, resultadosClassicDespues, resultadosBorutaDespues])\n",
    "resultadosAllDespues = resultadosAllDespues.drop(['Model.1'], axis=1)   \n",
    "resultadosAllDespues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordena resultadosAllDespues por MCC\n",
    "resultadosAllDespues = resultadosAllDespues.sort_values(by=['MCC'], ascending=False)\n",
    "resultadosAllDespues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En los siguientes codigos se realizan diferentes tipos de graficos para poder evaluar cual son los mejores modelos para poder crear el predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_test2(resultadosAllDespues, 'F1', 'Metodo', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_boxplot_test5(resultadosAll, ['MCC', 'F1', 'Kappa'], 'Model')\n",
    "create_boxplot_test2(resultadosAllDespues, 'F1', 'Model', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')\n",
    "create_boxplot_test2(resultadosAllDespues, 'MCC', 'Model', (10, 10), 'Metodos', 'MCC Score', 'MCC Score Comparison')\n",
    "create_boxplot_test2(resultadosAllDespues, 'Kappa', 'Model', (10, 10), 'Metodos', 'Kappa Score', 'Kappa Score Comparison')\n",
    "create_boxplot_test5(resultadosAllDespues, ['MCC', 'F1', 'Kappa'], 'Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_v2(resultadosAllDespues, 'MCC', 'Metodo', (10, 10), 'Metodos', 'MCC Score', 'MCC Score Comparison')\n",
    "create_boxplot_v2(resultadosAllDespues, 'F1', 'Metodo', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')\n",
    "create_boxplot_v2(resultadosAllDespues, 'Kappa', 'Metodo', (10, 10), 'Metodos', 'Kappa Score', 'Kappa Score Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_boxplot_v2(resultadosAllDespues, 'MCC', 'Model', (10, 10), 'Models', 'MCC Score', 'MCC Score Comparison')\n",
    "create_boxplot_v2(resultadosAllDespues, 'F1', 'Model', (10, 10), 'Models', 'MCC Score', 'F1 Score Comparison')\n",
    "create_boxplot_v2(resultadosAllDespues, 'Kappa', 'Model', (10, 10), 'Models', 'MCC Score', 'Kappa Score Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosAllDespues['Model'] = resultadosAllDespues['Model'] + 'balanceados'\n",
    "resultadosAllDespues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadosAll = pd.concat([resultadosAll, resultadosAllDespues])\n",
    "resultadosAll = resultadosAll.drop(['Accuracy', 'AUC', 'Recall', 'Prec.'], axis=1)\n",
    "resultadosAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_test2(resultadosAll, 'F1', 'Model', (10, 10), 'Metodos', 'F1 Score', 'F1 Score Comparison')\n",
    "create_boxplot_test2(resultadosAll, 'MCC', 'Model', (10, 10), 'Metodos', 'MCC Score', 'MCC Score Comparison')\n",
    "create_boxplot_test2(resultadosAll, 'Kappa', 'Model', (10, 10), 'Metodos', 'Kappa Score', 'Kappa Score Comparison')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_test5(resultadosAll, ['MCC', 'F1', 'Kappa'], 'Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_v2(resultadosAll, 'MCC', 'Model', (10, 10), 'Models', 'MCC Score', 'MCC Score Comparison')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crear el modelo lr boruta , lda boruta , gbc boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>PubchemFP9</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>type1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 882 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  PubchemFP5  \\\n",
       "0              1           1           1           0           0           0   \n",
       "1              1           1           1           0           0           0   \n",
       "2              1           1           1           0           0           0   \n",
       "3              1           1           1           0           0           0   \n",
       "4              1           1           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1109           1           1           1           0           0           0   \n",
       "1110           1           1           1           0           0           0   \n",
       "1111           1           1           1           0           0           0   \n",
       "1112           1           1           1           0           0           0   \n",
       "1113           1           1           1           1           0           0   \n",
       "\n",
       "      PubchemFP6  PubchemFP7  PubchemFP8  PubchemFP9  ...  PubchemFP872  \\\n",
       "0              0           0           0           1  ...             0   \n",
       "1              0           0           0           1  ...             0   \n",
       "2              0           0           0           1  ...             0   \n",
       "3              0           0           0           1  ...             0   \n",
       "4              0           0           0           1  ...             0   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1109           0           0           0           1  ...             0   \n",
       "1110           0           0           0           1  ...             0   \n",
       "1111           0           0           0           1  ...             0   \n",
       "1112           0           0           0           1  ...             0   \n",
       "1113           0           0           0           1  ...             0   \n",
       "\n",
       "      PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  \\\n",
       "0                0             0             0             0             0   \n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1109             0             0             0             0             0   \n",
       "1110             0             0             0             0             0   \n",
       "1111             0             0             0             0             0   \n",
       "1112             0             0             0             0             0   \n",
       "1113             0             0             0             0             0   \n",
       "\n",
       "      PubchemFP878  PubchemFP879  PubchemFP880  type1  \n",
       "0                0             0             0      1  \n",
       "1                0             0             0      1  \n",
       "2                0             0             0      1  \n",
       "3                0             0             0      1  \n",
       "4                0             0             0      1  \n",
       "...            ...           ...           ...    ...  \n",
       "1109             0             0             0      2  \n",
       "1110             0             0             0      2  \n",
       "1111             0             0             0      2  \n",
       "1112             0             0             0      2  \n",
       "1113             0             0             0      2  \n",
       "\n",
       "[1114 rows x 882 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Este código importa un archivo de Excel llamado \"resamplepadel.xlsx\" usando la biblioteca Pandas. Luego, crea una nueva columna llamada \"type1\" en el conjunto de datos, que contiene el valor 1 si la columna \"type\" contiene el valor \"IC50\", y 2 en caso contrario. Por último, elimina la columna \"type\" del conjunto de datos.\n",
    "import pandas as pd\n",
    "resamplepadel = pd.read_excel('resamplepadel.xlsx')\n",
    "resamplepadel\n",
    "importantesDespues = resamplepadel\n",
    "importantesDespues['type1'] = importantesDespues['type'].apply(lambda x: 1 if x == 'IC50' else 2)\n",
    "#drop type\n",
    "importantesDespues.drop(['type'], axis=1, inplace=True)\n",
    "importantesDespues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bf286_row10_col0, #T_bf286_row10_col1, #T_bf286_row10_col2, #T_bf286_row10_col3, #T_bf286_row10_col4, #T_bf286_row10_col5, #T_bf286_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bf286\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bf286_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_bf286_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_bf286_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_bf286_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_bf286_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_bf286_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_bf286_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bf286_row0_col0\" class=\"data row0 col0\" >0.9762</td>\n",
       "      <td id=\"T_bf286_row0_col1\" class=\"data row0 col1\" >0.9881</td>\n",
       "      <td id=\"T_bf286_row0_col2\" class=\"data row0 col2\" >0.9762</td>\n",
       "      <td id=\"T_bf286_row0_col3\" class=\"data row0 col3\" >0.9762</td>\n",
       "      <td id=\"T_bf286_row0_col4\" class=\"data row0 col4\" >0.9762</td>\n",
       "      <td id=\"T_bf286_row0_col5\" class=\"data row0 col5\" >0.9524</td>\n",
       "      <td id=\"T_bf286_row0_col6\" class=\"data row0 col6\" >0.9524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bf286_row1_col0\" class=\"data row1 col0\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row1_col3\" class=\"data row1 col3\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row1_col4\" class=\"data row1 col4\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row1_col5\" class=\"data row1 col5\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row1_col6\" class=\"data row1 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bf286_row2_col0\" class=\"data row2 col0\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row2_col1\" class=\"data row2 col1\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row2_col3\" class=\"data row2 col3\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row2_col4\" class=\"data row2 col4\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row2_col5\" class=\"data row2 col5\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row2_col6\" class=\"data row2 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bf286_row3_col0\" class=\"data row3 col0\" >0.9762</td>\n",
       "      <td id=\"T_bf286_row3_col1\" class=\"data row3 col1\" >0.9943</td>\n",
       "      <td id=\"T_bf286_row3_col2\" class=\"data row3 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row3_col3\" class=\"data row3 col3\" >0.9545</td>\n",
       "      <td id=\"T_bf286_row3_col4\" class=\"data row3 col4\" >0.9767</td>\n",
       "      <td id=\"T_bf286_row3_col5\" class=\"data row3 col5\" >0.9524</td>\n",
       "      <td id=\"T_bf286_row3_col6\" class=\"data row3 col6\" >0.9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bf286_row4_col0\" class=\"data row4 col0\" >0.9643</td>\n",
       "      <td id=\"T_bf286_row4_col1\" class=\"data row4 col1\" >0.9966</td>\n",
       "      <td id=\"T_bf286_row4_col2\" class=\"data row4 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row4_col3\" class=\"data row4 col3\" >0.9333</td>\n",
       "      <td id=\"T_bf286_row4_col4\" class=\"data row4 col4\" >0.9655</td>\n",
       "      <td id=\"T_bf286_row4_col5\" class=\"data row4 col5\" >0.9286</td>\n",
       "      <td id=\"T_bf286_row4_col6\" class=\"data row4 col6\" >0.9309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_bf286_row5_col0\" class=\"data row5 col0\" >0.9880</td>\n",
       "      <td id=\"T_bf286_row5_col1\" class=\"data row5 col1\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row5_col2\" class=\"data row5 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row5_col3\" class=\"data row5 col3\" >0.9767</td>\n",
       "      <td id=\"T_bf286_row5_col4\" class=\"data row5 col4\" >0.9882</td>\n",
       "      <td id=\"T_bf286_row5_col5\" class=\"data row5 col5\" >0.9759</td>\n",
       "      <td id=\"T_bf286_row5_col6\" class=\"data row5 col6\" >0.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_bf286_row6_col0\" class=\"data row6 col0\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row6_col1\" class=\"data row6 col1\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row6_col2\" class=\"data row6 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row6_col4\" class=\"data row6 col4\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row6_col5\" class=\"data row6 col5\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row6_col6\" class=\"data row6 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_bf286_row7_col0\" class=\"data row7 col0\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row7_col1\" class=\"data row7 col1\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row7_col2\" class=\"data row7 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row7_col4\" class=\"data row7 col4\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row7_col5\" class=\"data row7 col5\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row7_col6\" class=\"data row7 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_bf286_row8_col0\" class=\"data row8 col0\" >0.9759</td>\n",
       "      <td id=\"T_bf286_row8_col1\" class=\"data row8 col1\" >0.9977</td>\n",
       "      <td id=\"T_bf286_row8_col2\" class=\"data row8 col2\" >0.9756</td>\n",
       "      <td id=\"T_bf286_row8_col3\" class=\"data row8 col3\" >0.9756</td>\n",
       "      <td id=\"T_bf286_row8_col4\" class=\"data row8 col4\" >0.9756</td>\n",
       "      <td id=\"T_bf286_row8_col5\" class=\"data row8 col5\" >0.9518</td>\n",
       "      <td id=\"T_bf286_row8_col6\" class=\"data row8 col6\" >0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_bf286_row9_col0\" class=\"data row9 col0\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row9_col1\" class=\"data row9 col1\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row9_col4\" class=\"data row9 col4\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row9_col5\" class=\"data row9 col5\" >1.0000</td>\n",
       "      <td id=\"T_bf286_row9_col6\" class=\"data row9 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_bf286_row10_col0\" class=\"data row10 col0\" >0.9881</td>\n",
       "      <td id=\"T_bf286_row10_col1\" class=\"data row10 col1\" >0.9977</td>\n",
       "      <td id=\"T_bf286_row10_col2\" class=\"data row10 col2\" >0.9952</td>\n",
       "      <td id=\"T_bf286_row10_col3\" class=\"data row10 col3\" >0.9816</td>\n",
       "      <td id=\"T_bf286_row10_col4\" class=\"data row10 col4\" >0.9882</td>\n",
       "      <td id=\"T_bf286_row10_col5\" class=\"data row10 col5\" >0.9761</td>\n",
       "      <td id=\"T_bf286_row10_col6\" class=\"data row10 col6\" >0.9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf286_level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "      <td id=\"T_bf286_row11_col0\" class=\"data row11 col0\" >0.0131</td>\n",
       "      <td id=\"T_bf286_row11_col1\" class=\"data row11 col1\" >0.0037</td>\n",
       "      <td id=\"T_bf286_row11_col2\" class=\"data row11 col2\" >0.0096</td>\n",
       "      <td id=\"T_bf286_row11_col3\" class=\"data row11 col3\" >0.0220</td>\n",
       "      <td id=\"T_bf286_row11_col4\" class=\"data row11 col4\" >0.0128</td>\n",
       "      <td id=\"T_bf286_row11_col5\" class=\"data row11 col5\" >0.0261</td>\n",
       "      <td id=\"T_bf286_row11_col6\" class=\"data row11 col6\" >0.0256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1340845d340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3521576ff3194a91aba2a33340428893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Hyperparameters', 'param…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9d9b5cfb0a49d9a5298ca794f166f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Hyperparameters', 'param…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f79f074372646c481cacec66e2ffb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Hyperparameters', 'param…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Este código establece una configuración para un modelo de aprendizaje automático. Establece los datos, el objetivo y el tamaño del conjunto de entrenamiento. Luego, crea tres modelos diferentes (regresión logística, análisis discriminante lineal y árboles de decisión gradiente) y los ajusta para optimizar sus resultados. Finalmente, evalúa los modelos y realiza predicciones con cada uno de ellos.\n",
    "exp_clf1 = setup(data = importantesDespues, target = 'type1', train_size=0.75, data_split_stratify=True, use_gpu=True, feature_selection=True, silent=True,feature_selection_method=\"classic\")\n",
    "\n",
    "lrPREDICCIONS = create_model('lr')\n",
    "#tunea el modelo\n",
    "tuned_lrPREDICCIONS = tune_model(lrPREDICCIONS)\n",
    "ldaPREDICCIONS = create_model('lda')\n",
    "#tunea el modelo\n",
    "tuned_ldaPREDICCIONS = tune_model(ldaPREDICCIONS)\n",
    "\n",
    "gbcPREDICCIONS = create_model('gbc')\n",
    "#tunea el modelo\n",
    "tuned_gbcPREDICCIONS = tune_model(gbcPREDICCIONS)\n",
    "\n",
    "evaluate_model(lrPREDICCIONS)\n",
    "evaluate_model(ldaPREDICCIONS)\n",
    "evaluate_model(gbcPREDICCIONS)\n",
    "\n",
    "predictions_lr = predict_model(lrPREDICCIONS, data=importantesDespues)\n",
    "predictions_lda = predict_model(ldaPREDICCIONS, data=importantesDespues)\n",
    "predictions_gbc = predict_model(gbcPREDICCIONS, data=importantesDespues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>PubchemFP9</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>type1</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 884 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  PubchemFP5  \\\n",
       "0              1           1           1           0           0           0   \n",
       "1              1           1           1           0           0           0   \n",
       "2              1           1           1           0           0           0   \n",
       "3              1           1           1           0           0           0   \n",
       "4              1           1           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1109           1           1           1           0           0           0   \n",
       "1110           1           1           1           0           0           0   \n",
       "1111           1           1           1           0           0           0   \n",
       "1112           1           1           1           0           0           0   \n",
       "1113           1           1           1           1           0           0   \n",
       "\n",
       "      PubchemFP6  PubchemFP7  PubchemFP8  PubchemFP9  ...  PubchemFP874  \\\n",
       "0              0           0           0           1  ...             0   \n",
       "1              0           0           0           1  ...             0   \n",
       "2              0           0           0           1  ...             0   \n",
       "3              0           0           0           1  ...             0   \n",
       "4              0           0           0           1  ...             0   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1109           0           0           0           1  ...             0   \n",
       "1110           0           0           0           1  ...             0   \n",
       "1111           0           0           0           1  ...             0   \n",
       "1112           0           0           0           1  ...             0   \n",
       "1113           0           0           0           1  ...             0   \n",
       "\n",
       "      PubchemFP875  PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  \\\n",
       "0                0             0             0             0             0   \n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1109             0             0             0             0             0   \n",
       "1110             0             0             0             0             0   \n",
       "1111             0             0             0             0             0   \n",
       "1112             0             0             0             0             0   \n",
       "1113             0             0             0             0             0   \n",
       "\n",
       "      PubchemFP880  type1  Label   Score  \n",
       "0                0      1      1  0.9935  \n",
       "1                0      1      1  0.9974  \n",
       "2                0      1      1  0.9980  \n",
       "3                0      1      1  0.9981  \n",
       "4                0      1      1  0.9945  \n",
       "...            ...    ...    ...     ...  \n",
       "1109             0      2      2  0.9960  \n",
       "1110             0      2      2  0.9854  \n",
       "1111             0      2      2  0.9814  \n",
       "1112             0      2      2  0.9979  \n",
       "1113             0      2      2  0.9973  \n",
       "\n",
       "[1114 rows x 884 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>PubchemFP9</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>type1</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 884 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  PubchemFP5  \\\n",
       "0              1           1           1           0           0           0   \n",
       "1              1           1           1           0           0           0   \n",
       "2              1           1           1           0           0           0   \n",
       "3              1           1           1           0           0           0   \n",
       "4              1           1           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1109           1           1           1           0           0           0   \n",
       "1110           1           1           1           0           0           0   \n",
       "1111           1           1           1           0           0           0   \n",
       "1112           1           1           1           0           0           0   \n",
       "1113           1           1           1           1           0           0   \n",
       "\n",
       "      PubchemFP6  PubchemFP7  PubchemFP8  PubchemFP9  ...  PubchemFP874  \\\n",
       "0              0           0           0           1  ...             0   \n",
       "1              0           0           0           1  ...             0   \n",
       "2              0           0           0           1  ...             0   \n",
       "3              0           0           0           1  ...             0   \n",
       "4              0           0           0           1  ...             0   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1109           0           0           0           1  ...             0   \n",
       "1110           0           0           0           1  ...             0   \n",
       "1111           0           0           0           1  ...             0   \n",
       "1112           0           0           0           1  ...             0   \n",
       "1113           0           0           0           1  ...             0   \n",
       "\n",
       "      PubchemFP875  PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  \\\n",
       "0                0             0             0             0             0   \n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1109             0             0             0             0             0   \n",
       "1110             0             0             0             0             0   \n",
       "1111             0             0             0             0             0   \n",
       "1112             0             0             0             0             0   \n",
       "1113             0             0             0             0             0   \n",
       "\n",
       "      PubchemFP880  type1  Label  Score  \n",
       "0                0      1      1    1.0  \n",
       "1                0      1      1    1.0  \n",
       "2                0      1      1    1.0  \n",
       "3                0      1      1    1.0  \n",
       "4                0      1      1    1.0  \n",
       "...            ...    ...    ...    ...  \n",
       "1109             0      2      2    1.0  \n",
       "1110             0      2      2    1.0  \n",
       "1111             0      2      2    1.0  \n",
       "1112             0      2      2    1.0  \n",
       "1113             0      2      2    1.0  \n",
       "\n",
       "[1114 rows x 884 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>PubchemFP9</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>type1</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 884 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  PubchemFP5  \\\n",
       "0              1           1           1           0           0           0   \n",
       "1              1           1           1           0           0           0   \n",
       "2              1           1           1           0           0           0   \n",
       "3              1           1           1           0           0           0   \n",
       "4              1           1           1           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1109           1           1           1           0           0           0   \n",
       "1110           1           1           1           0           0           0   \n",
       "1111           1           1           1           0           0           0   \n",
       "1112           1           1           1           0           0           0   \n",
       "1113           1           1           1           1           0           0   \n",
       "\n",
       "      PubchemFP6  PubchemFP7  PubchemFP8  PubchemFP9  ...  PubchemFP874  \\\n",
       "0              0           0           0           1  ...             0   \n",
       "1              0           0           0           1  ...             0   \n",
       "2              0           0           0           1  ...             0   \n",
       "3              0           0           0           1  ...             0   \n",
       "4              0           0           0           1  ...             0   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1109           0           0           0           1  ...             0   \n",
       "1110           0           0           0           1  ...             0   \n",
       "1111           0           0           0           1  ...             0   \n",
       "1112           0           0           0           1  ...             0   \n",
       "1113           0           0           0           1  ...             0   \n",
       "\n",
       "      PubchemFP875  PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  \\\n",
       "0                0             0             0             0             0   \n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1109             0             0             0             0             0   \n",
       "1110             0             0             0             0             0   \n",
       "1111             0             0             0             0             0   \n",
       "1112             0             0             0             0             0   \n",
       "1113             0             0             0             0             0   \n",
       "\n",
       "      PubchemFP880  type1  Label   Score  \n",
       "0                0      1      1  0.9919  \n",
       "1                0      1      1  0.9990  \n",
       "2                0      1      1  0.9991  \n",
       "3                0      1      1  0.9991  \n",
       "4                0      1      1  0.9990  \n",
       "...            ...    ...    ...     ...  \n",
       "1109             0      2      2  0.9964  \n",
       "1110             0      2      2  0.9918  \n",
       "1111             0      2      2  0.9895  \n",
       "1112             0      2      2  0.9970  \n",
       "1113             0      2      2  0.9981  \n",
       "\n",
       "[1114 rows x 884 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_gbc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCIONES CON EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crea un dataframe vacio\n",
    "df3_class = pd.DataFrame()\n",
    "#crea una columna llamada canonical_smiles\n",
    "df3_class['canonical_smiles'] = ['COc1cc(CC(=O)OCC2=C[C@H]3[C@H]4OC5(Cc6ccccc6)O[C@@]4(C[C@@H](C)[C@]3(O5)[C@@H]3C=C(C)C(=O)[C@@]3(O)C2)C(C)=C)ccc1O']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1cc(CC(=O)OCC2=C[C@H]3[C@H]4OC5(Cc6ccccc6)O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    canonical_smiles\n",
       "0  COc1cc(CC(=O)OCC2=C[C@H]3[C@H]4OC5(Cc6ccccc6)O..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COc1cc(CC(=O)OCC2=C[C@H]3[C@H]4OC5(Cc6ccccc6)O[C@@]4(C[C@@H](C)[C@]3(O5)[C@@H]3C=C(C)C(=O)[C@@]3(O)C2)C(C)=C)ccc1O\n",
      "\n",
      "1\n",
      "java -Xms1G -Xmx1G -Djava.awt.headless=true -jar ./PaDEL-Descriptor/PaDEL-Descriptor.jar -removesalt -standardizenitro -fingerprints -descriptortypes ./PaDEL-Descriptor/PubchemFingerprinter.xml -dir ./ -file descriptors_output.csv\n",
      "\n",
      "Processing AUTOGEN_molecule in molecule.smi (1/1). \n",
      "Descriptor calculation completed in 0.778 secs . Average speed: 0,78 s/mol.\n"
     ]
    }
   ],
   "source": [
    "#Este código importa la biblioteca zipfile, extrae el archivo zip \"padel.zip\" y guarda los datos en un archivo de texto llamado \"molecule.smi\". Luego imprime las primeras 5 líneas del archivo de texto y cuenta el número total de líneas en el archivo. Después, imprime todas las líneas del archivo \"padel.sh\", cambia los permisos para que el archivo sea ejecutable y ejecuta el script con la salida redirigida a un archivo de registro llamado \"log.txt\". Finalmente, imprime el contenido del archivo de registro.\n",
    "import zipfile\n",
    "with zipfile.ZipFile('padel.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "selection = ['canonical_smiles']\n",
    "df3_selection = df3_class[selection]\n",
    "df3_selection.to_csv('molecule.smi', sep='\\t', index=False, header=False)\n",
    "df3_selection.head(100)\n",
    "\n",
    "with open(\"molecule.smi\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:5]:\n",
    "        print(line)\n",
    "\n",
    "\n",
    "with open(\"molecule.smi\") as f:\n",
    "    lines = f.readlines()\n",
    "    num_lines = len(lines)\n",
    "    print(num_lines)\n",
    "\n",
    "with open(\"padel.sh\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "\n",
    "\n",
    "import os\n",
    "os.chmod('padel.sh', 0o777)\n",
    "os.getcwd()\n",
    "import os\n",
    "os.environ['PATH'] += os.pathsep + 'C:/Program Files/Git/usr/bin'\n",
    "!bash padel.sh > log.txt\n",
    "!cat log.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP871</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOGEN_molecule</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 882 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  \\\n",
       "0  AUTOGEN_molecule           1           0           0           0   \n",
       "\n",
       "   PubchemFP4  PubchemFP5  PubchemFP6  PubchemFP7  PubchemFP8  ...  \\\n",
       "0           0           0           0           0           0  ...   \n",
       "\n",
       "   PubchemFP871  PubchemFP872  PubchemFP873  PubchemFP874  PubchemFP875  \\\n",
       "0             0             0             0             0             0   \n",
       "\n",
       "   PubchemFP876  PubchemFP877  PubchemFP878  PubchemFP879  PubchemFP880  \n",
       "0             0             0             0             0             0  \n",
       "\n",
       "[1 rows x 882 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Este código lee un archivo CSV llamado descriptors_output.csv y lo almacena en una variable llamada df3_X. Luego imprime el contenido de la variable df3_X para ver los datos que contiene el archivo CSV.\n",
    "df3_X = pd.read_csv('descriptors_output.csv')\n",
    "df3_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CON ESTE CODIGO DE REALIZAN LAS PREDICCIONES\n",
    "predictions_lr = predict_model(tuned_lrPREDICCIONS, data=df3_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOGEN_molecule</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 884 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  \\\n",
       "0  AUTOGEN_molecule           1           0           0           0   \n",
       "\n",
       "   PubchemFP4  PubchemFP5  PubchemFP6  PubchemFP7  PubchemFP8  ...  \\\n",
       "0           0           0           0           0           0  ...   \n",
       "\n",
       "   PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  \\\n",
       "0             0             0             0             0             0   \n",
       "\n",
       "   PubchemFP878  PubchemFP879  PubchemFP880  Label   Score  \n",
       "0             0             0             0      1  0.9036  \n",
       "\n",
       "[1 rows x 884 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOGEN_molecule</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>IC50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 885 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  \\\n",
       "0  AUTOGEN_molecule           1           0           0           0   \n",
       "\n",
       "   PubchemFP4  PubchemFP5  PubchemFP6  PubchemFP7  PubchemFP8  ...  \\\n",
       "0           0           0           0           0           0  ...   \n",
       "\n",
       "   PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  PubchemFP878  \\\n",
       "0             0             0             0             0             0   \n",
       "\n",
       "   PubchemFP879  PubchemFP880  Label   Score  type  \n",
       "0             0             0      1  0.9036  IC50  \n",
       "\n",
       "[1 rows x 885 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr['type'] = predictions_lr['Label'].apply(lambda x: 'IC50' if x == 1 else 'EC50')\n",
    "predictions_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Succesfully Saved\n",
      "Transformation Pipeline and Model Succesfully Saved\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=[], target='type1',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=None,\n",
       "                                 numeric_strat...\n",
       "                                             loss='deviance', max_depth=3,\n",
       "                                             max_features=1.0,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0005,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=9,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=8124, subsample=0.8,\n",
       "                                             tol=0.0001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False)]],\n",
       "          verbose=False),\n",
       " 'gbcPREDICCIONS.pkl')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El siguiente codigo guarda los modelos\n",
    "save_model(tuned_lrPREDICCIONS, 'lrPREDICCIONS')\n",
    "save_model(tuned_ldaPREDICCIONS, 'ldaPREDICCIONS')\n",
    "save_model(tuned_gbcPREDICCIONS, 'gbcPREDICCIONS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(tuned_lrPREDICCIONS, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(tuned_ldaPREDICCIONS, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(tuned_gbcPREDICCIONS, plot = 'auc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8ee14b8c728d13592de9d270a0984bc28bc415e0a147d19d15ffd248cda7f2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
